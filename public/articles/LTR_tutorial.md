---
title: "从排序算法到 LambdaRank：让机器学会“谁更重要”"
date: "2025-11-12"
tags: ["搜索算法", "排序", "机器学习"]
excerpt: "对排序学习的简介"
---

# 从排序算法到 LambdaRank：让机器学会“谁更重要”

在搜索引擎、推荐系统和广告排序中，最核心的问题是：
给定一个查询或用户，我们如何判断哪些结果更重要、更相关？

这类问题被称为 **学习排序（Learning to Rank, LTR）**。
本文将从排序算法的基本概念讲起，逐步介绍 **RankNet** 的思路，并深入讲解 **LambdaRank** 如何在此基础上改进，使模型能直接优化排序指标（如 NDCG）。

![排序算法](/MyBlog/images/LTR_tutorial/image.png)

---

## 一、排序算法的动机

设想用户在搜索“咖啡机”，系统检索到上千个候选网页。
问题在于：哪些网页应该排在前面？

传统搜索依赖人工规则（如 PageRank、关键词匹配），这些规则固化且难以反映真实用户需求。
学习排序的思想是：

> 用机器学习模型，从用户历史行为（如点击、停留时间等）中学习一个排序函数，使其能自动判断结果的优劣顺序。

---

## 二、学习排序的三种基本思路

学习排序主要有三种典型方法：**Pointwise、Pairwise、Listwise**。

| 方法类型          | 目标            | 优点      | 缺点         |
| ------------- | ------------- | ------- | ---------- |
| Pointwise（点式） | 预测每个文档的相关性分数  | 简单直接    | 忽略文档间顺序关系  |
| Pairwise（对式）  | 比较文档两两之间的优劣   | 能学习相对顺序 | 仍间接优化排序指标  |
| Listwise（列式）  | 直接优化整个结果列表的指标 | 理论最优    | 实现复杂、计算代价高 |

接下来我们重点关注 Pairwise 思想，因为 RankNet 与 LambdaRank 都属于这一类。

---

## 三、RankNet：从两两比较中学习排序

RankNet 是微软研究院在 2005 年提出的一种基于神经网络的排序算法。
它的核心思想是：

> 模型不直接预测文档的绝对分数，而是比较两个文档，判断哪个更相关。

### 1. 数据结构

每个训练样本是一条查询（query）和一组候选文档（documents）：

```
Query: "咖啡机"
  - D1: 特征向量 [f1, f2, ...], relevance = 3
  - D2: 特征向量 [f1, f2, ...], relevance = 2
  - D3: 特征向量 [f1, f2, ...], relevance = 0
```

其中“相关性标签”通常来自人工标注或用户点击日志。

---

### 2. 模型输出

神经网络输入文档特征，输出一个实数分数 $s_i$，代表模型认为该文档的相关性。

| 文档 | 模型输出分数 |
| -- | ------ |
| D1 | 0.82   |
| D2 | 0.60   |
| D3 | 0.10   |

分数高的文档会被排在前面。

---

### 3. Pairwise 概率建模

RankNet 关心的是文档之间的相对顺序。
对于任意文档对 $(D_i, D_j)$，定义：

$$
P_{ij} = \frac{1}{1 + e^{-(s_i - s_j)}}
$$

其中 $P_{ij}$ 表示模型认为“$D_i$ 比 $D_j$ 更相关”的概率。

真实标签 $y_{ij}$ 为：

$$
y_{ij} =
\begin{cases}
1, & \text{如果 } D_i \text{ 更相关} \
0, & \text{如果 } D_j \text{ 更相关}
\end{cases}
$$

---

### 4. 损失函数

RankNet 使用交叉熵损失：

$$
Loss_{ij} = -y_{ij}\log(P_{ij}) - (1 - y_{ij})\log(1 - P_{ij})
$$

优化目标是让模型输出的顺序概率接近真实顺序。

---

### 5. 参数更新

RankNet 通过反向传播计算梯度。
对文档 $i$ 的打分 $s_i$，梯度为：

$$
\lambda_{ij}^{RankNet} = -\sigma \cdot \frac{1}{1 + e^{\sigma (s_i - s_j)}}
$$

其中 $\sigma$ 是平滑系数（通常取 1）。
模型通过这些梯度调整参数，使排序越来越接近理想顺序。

---

### 6. RankNet 的问题

RankNet 的不足主要有两点：

1. **所有文档对权重相同**
   把第 1 名和第 10 名弄反，与把第 9 名和第 10 名弄反受到的惩罚一样，
   而实际前者对用户体验影响更大。

2. **优化目标间接**
   RankNet 优化的是 pairwise 概率，而搜索排序的最终指标（如 NDCG、MAP）并不完全一致。

这些问题为 LambdaRank 的出现铺平了道路。

---

## 四、LambdaRank：引入排序指标的重要性

LambdaRank（2007）由微软研究院提出，
它继承了 RankNet 的 Pairwise 思想，但在梯度计算中引入了“权重 λ（Lambda）”，
用以衡量**某个错误对整体排序质量的影响程度**。

---

### 1. 基本思想

LambdaRank 的核心是：

> 在每个样本对的梯度中，乘上一个与排序指标（NDCG）变化量相关的权重。

这意味着模型会更关注那些对排序质量影响大的错误。
例如：

* 把第 1 名错排到第 10 名 → 惩罚更大；
* 把第 9 名错排到第 10 名 → 惩罚较小。

---

### 2. NDCG 指标回顾

NDCG（Normalized Discounted Cumulative Gain）衡量一个搜索结果列表的质量：

$$
NDCG = \frac{1}{Z} \sum_{k=1}^{n} \frac{2^{rel_k} - 1}{\log_2(1 + k)}
$$

其中：

* $rel_k$：第 $k$ 个文档的相关性标签
* $\log_2(1 + k)$ 是折损因子（越靠后权重越小）
* $Z$：归一化常数，用理想排序的 DCG 归一化

---

### 3. 计算权重 λ

当我们交换文档 $i$ 和 $j$ 时，NDCG 会发生变化：

$$
\Delta NDCG_{ij} = |(G_i - G_j)(D_i - D_j)|
$$

其中：

* $G_i = 2^{rel_i} - 1$ 表示文档的“增益”；
* $D_i = 1 / \log_2(1 + rank_i)$ 表示位置的折损。

LambdaRank 将 RankNet 的梯度乘上该变化量：

$$
\lambda_{ij} = -\sigma \cdot \frac{1}{1 + e^{\sigma (s_i - s_j)}} \cdot |\Delta NDCG_{ij}|
$$

最终每个文档的总梯度是：

$$
\lambda_i = \sum_j \lambda_{ij}
$$

---

### 4. 实际意义

λ 的大小表示“这个错误对最终排名指标有多大影响”。

* 如果交换第 1 和第 2 名，$\Delta NDCG$ 较大，λ 也大；
* 如果交换第 9 和第 10 名，$\Delta NDCG$ 较小，λ 也小。

模型更新时就会更集中优化那些关键错误，从而直接提升最终的排序质量。

---

## 五、LambdaRank 与 RankNet 的对比

| 项目   | RankNet       | LambdaRank          |
| ---- | ------------- | ------------------- |
| 思想   | Pairwise 比较   | Pairwise + NDCG 加权  |
| 梯度权重 | 所有样本对权重相同     | 根据 $\Delta NDCG$ 调整 |
| 优化目标 | Pairwise 顺序概率 | 排序指标（如 NDCG）        |
| 效果   | 能学顺序          | 能学“有价值的顺序”          |

LambdaRank 的 λ 权重机制，使得模型训练方向与业务评估指标更加一致。

---

## 六、LambdaRank 的意义与演化

LambdaRank 在工业界产生了深远影响。
微软研究员随后将其与梯度提升树（GBDT）结合，提出了 **LambdaMART**，
这是目前最常用的排序算法之一（如 LightGBM、XGBoost 的 rank 模式）。

LambdaRank 的核心贡献在于：

* 把排序指标的变化量引入训练过程；
* 让模型的优化目标与评估指标直接对齐；
* 保留了 RankNet 的可微结构，便于梯度学习。

---

## 七、总结

1. **学习排序（LTR）** 旨在让模型自动学会“结果排序”的规则。
2. **RankNet** 用 pairwise 学习思想，让模型学会比较两个文档的相对顺序。
3. **LambdaRank** 在 RankNet 的基础上引入 NDCG 权重（λ），
   让梯度更新与排序指标直接相关。
4. **LambdaMART** 将这一思想与树模型结合，实现了高效且强大的排序性能。

简而言之：

> RankNet 让模型“学会排序”，
> LambdaRank 让模型“学会优化真正重要的排序”。

