---
title: "Context Engineering Discussion by Lance and Peak"
date: "2025-10-16"
tags: ["Agent", "Context Engineering", "Manus"]
excerpt: "Lance and Peak discuss Context Engineering"
---

# Context Engineering Discussion by Lance and Peak

## Introduction

这是我从 YouTube 上转录并翻译的一段关于 **Context Engineering** 的讨论。  
由 LangChain 的创始人 **Lance** 和 Manus 的创始人 **Peak** 共同主持。

- 🎥 [YouTube 视频](https://www.youtube.com/watch?v=6_BcCthVvb8&list=WL)
- 📊 [Lance Martin 的演示文稿（LangChain）](https://docs.google.com/presentation/d/16aaXLu40GugY-kOpqDU4e-S0hD1FmHcNyF0rRRnb1OU/edit?slide=id.p#slide=id.p)
- 📘 [Yichao “Peak” Ji 的演示文稿（Manus）](https://drive.google.com/file/d/1QGJ-BrdiTGslS71sYH4OJoidsry3Ps9g/view)


## Lance and Peak's Discussion
**Lance:**

好了，非常感谢大家的到来，我们现在就开始这次的网络研讨会，我相信还会有更多人陆续加入。我是 Lance，LangChain 的创始工程师之一。今天和我一起分享的还有来自 Man画s 的 Pete。

Pete，你想先简单介绍一下自己吗？

**Peak:**

好的，大家好！我是 Manus 的联合创始人兼首席科学家。基本上，我设计了 Manus 的 Agent 框架以及其中的许多东西。今天能来到这里我非常兴奋，感谢 Lance 的邀请。

**Lance:**

是的，我们也非常激动能举办这次活动，因为首先，Manus 是一个非常酷的产品，我已经使用它很长时间了。而且，几个月前他们发表了一篇关于“上下文工程”（Context Engineering）的非常棒的博客文章，对我影响很大。所以，我想先快速概述一下我所理解的“上下文工程”，并会引用他们的文章。然后，Pete 会做一个演讲，谈论一些文章中没有涵盖的新想法。所以，如果你已经读过那篇文章，他也会分享一些全新的内容，希望你们会觉得非常有趣。

我会先做个开场白，然后把时间交给 Pete，最后我们再进行问答环节。

你可能在今年早些时候听过“上下文工程”这个术语。如果你回顾 Google 搜索趋势的时间线，会发现“提示词工程”（Prompt Engineering）这个概念是在 ChatGPT 发布后开始兴起的——也就是 2022 年 12 月。当我们有了聊天模型这个新事物后，人们开始对如何给它们写提示词产生了巨大的兴趣，“提示词工程”作为一个与聊天模型交互和编写提示词的学科应运而生。

而“上下文工程”则是在今年 5 月份左右出现的，我们看到它在 Google 趋势中迅速崛起，这与“Agent 之年”的理念有些关联。为什么会这样呢？

如果你一直在构建 Agent，你会发现一个现象：上下文会以一种非常特殊的方式增长。我说的具体点，就是我们有一个大语言模型（LLM）绑定了一些工具，这个 LLM 可以在一个循环中自主调用这些工具。挑战在于，每一次工具调用，你都会得到一个工具的观测结果（observation）返回，这个结果会被追加到聊天消息列表中。随着时间的推移，这些消息会不断增长，所以当 Agent 运行时，你可能会遇到消息的无限制爆炸。

举个例子，Manus 在他们的文章中提到，典型的任务大约需要 50 次工具调用。Anthropic 也类似地提到，生产环境中的 Agent 可能会进行长达数百轮的对话。所以挑战就是，因为 Agent 越来越需要长时间自主运行，并且会自由地使用工具，通过工具调用的不断累积，你会积累大量的上下文。

Anthropic 发表了一篇非常好的关于“上下文衰减”（context rot）的报告，其观察结果很简单：随着上下文的增长，模型性能会下降。

这就产生了一个悖论，一个充满挑战的局面：Agent 因为工具调用而需要使用大量上下文，但我们又知道随着上下文的增长，性能会下降。这是我们许多人面临的挑战，我认为它催生了或孕育了“上下文工程”这个术语。当然，Anthropic 今年早些时候在 Twitter 上创造了这个词。

你可以把“上下文工程”看作是“用恰到好处的信息填充上下文窗口，以供下一步决策使用的精巧艺术与科学”。它试图对抗在构建 Agent 并让其自由调用工具时发生的上下文爆炸问题。当所有工具消息在你的消息队列中累积时，我们如何进行筛选，以便在任何时刻都能为 Agent 提供正确的信息，使其做出正确的下一步决策？

为了解决这个问题，我想强调几个我们在许多不同工作中看到的共同主题，包括 Manus 的工作，我稍后会提到。

**想法一：上下文卸载 (Context Offloading)**
我们一次又一次地看到这个趋势。核心思想是，你不需要把所有上下文都保存在 Agent 的消息历史中。你可以把信息拿出来，卸载到别的地方。这样它就在上下文窗口之外，但可以被检索回来，我们后面会谈到这一点。

这里最流行的想法之一就是使用文件系统。例如，将工具消息的输出转储到文件系统，然后只向你的 Agent 发回一些必要的最简信息，以便它在需要时可以引用完整的上下文。但像网页搜索结果这种非常消耗 token 的完整内容，就不会永远地塞满你的上下文窗口。我们看到很多项目都在使用这种方法。Manus 用了这个，我们有一个叫 Deep Agents 的项目也利用了文件系统。OpenDevin Research 实际上也用到了 Agent 状态（agent state），其作用类似于外部文件系统。当然，Claude Code 非常广泛地使用了它，长时间运行的 Agent 也非常广泛地使用它。所以，将上下文卸载到文件系统的想法在今天我们看到的许多生产级 Agent 示例中都非常普遍和流行。

**想法二：上下文精简 (Reducing Context)**
卸载非常简单，就是把一些信息——比如一个高 token 消耗的工具消息——不全部返回到你的消息列表，而是把它转储到一个文件系统，只有在需要时才去检索。这就是卸载。精简上下文类似，但它只是对信息进行总结或压缩。

一个很直观的方法是总结工具调用的输出。例如，我们在 OpenDevin Research 中就这么做。另一个方法是“剪枝”（pruning）工具调用或工具消息。一个非常有趣的事情是，Claude 3.5 Sonnet 实际上已经把这个功能加入了进来。如果你看他们最近的一些发布，他们现在已经原生支持这个功能。所以，用工具输出或工具消息来剪枝旧的工具调用的想法，现在 Claude 已经内置到了他们的 SDK 中。

总结或压缩完整的消息历史记录。你在 Claude Code 的压缩功能中能看到这一点。一旦你达到总上下文窗口的某个百分比，它就会进行压缩。Cognition 也谈到了在 Agent 之间交接工作时进行总结或剪枝的想法。所以，精简上下文是一个非常流行的主题，我们从 Claude Code 到我们的 OpenDevin Research，再到 Cognition，以及 Claude 3.5 Sonnet 等许多例子中都看到了。

**想法三：上下文检索 (Retrieving Context)**
这是今天你可能在 X（Twitter）上看到激烈争论的经典话题之一。检索上下文的正确方法是什么？Cursor 的 Lee Robinson 最近在 OpenAI Demo Day 上做了一个非常精彩的演讲（我会确保这些幻灯片都分享出来，这样你们可以看到这些链接）。他谈到，例如 Cursor 就使用了索引和语义搜索，以及一些更简单的基于文件的搜索工具，比如 `glob` 和 `grep`。而 Claude Code 则只使用文件系统和简单的搜索工具，特别是 `glob` 和 `grep`。所以，为你的 Agent 按需检索上下文有不同的方式。索引和像语义搜索这样的东西，以及文件系统和简单的文件搜索工具，两者都可以非常有效。它们各有优缺点，我们可以在问答环节讨论。但显然，上下文检索对于构建高效的 Agent 至关重要。

**想法四：上下文隔离 (Context Isolation)**
这是我们看到的另一个主要主题，特别是在多 Agent 之间划分上下文。这里的要点是什么呢？每个子 Agent 都有自己的上下文窗口，子 Agent 允许关注点分离（separation of concerns）。Manus 的 Wide Agents 谈到了这一点，我们的 Deep Agents 工作也使用了它，OpenDevin Research 也使用了它，Claude 的研究中也使用了子 Agent……在 Claude 的多 Agent 研究员（multi-agent researcher）中也使用了子 Agent，而且 Claude Code 也支持子 Agent。所以，子 Agent 是我们看到许多项目都在使用的一种非常常见的实现上下文隔离的方式。

现在，有一点我觉得非常有趣，那就是**缓存上下文 (Caching Context)**，Manus 在这方面谈了很多。稍后我会让 Peak 谈谈这一点，但我认为这也是一个非常有趣的技巧。

我只想展示一个我们在 OpenDevin Research 中看到的简单例子。这是我们一个非常受欢迎的仓库，它基本上是一个开源的深度研究（deep research）实现，其表现与一些最好的实现相当。你可以查看我们的仓库，我们有来自 Deep Research Bench 的结果，显示我们排在前十。

它有三个阶段：研究范围界定、研究阶段本身（使用多 Agent 架构），以及最后的一步到位写作阶段。
我们使用**卸载**：我们基本上创建一个摘要（brief）来界定我们的研究计划，然后我们卸载它，而不是简单地把它保存在上下文窗口里，因为那个上下文窗口会被其他东西填满。我们把它卸载掉，这样它就独立保存，可以从我们的 LangGraph 状态中访问，当然也可以从文件系统中访问，原理是一样的。所以你创建一个研究计划，卸载它，它就一直可以被访问。然后你去做一大堆工作，可以按需把它拉回来，比如放在你的消息列表末尾，这样你的 Agent 就可以随时方便地使用它来执行写作阶段。

正如你所看到的，我们使用**卸载**来帮助引导研究和写作阶段。
我们使用**精简**来总结来自高 token 消耗的搜索工具调用的观察结果，这在研究阶段内部完成。
我们在研究阶段内部的子 Agent 之间使用**上下文隔离**。

这基本上是我对许多不同项目中各种想法的总结。接下来 Peak 将具体谈谈 Manus 以及他们学到的一些经验教训。我这部分只是为他做个铺垫。

这只是总结了我刚才提到的不同主题：卸载、精简、检索、隔离、缓存上下文，以及一些流行项目和它们使用的位置。还有一些链接，我会把这些幻灯片分享到笔记中。

我现在想让 Peak 开始他的演讲，因为我想确保他有充足的时间，并且我们也有时间进行问答。这只是一个引子，Pete，现在交给你了，我停止分享。

**Peak:**

好的，你能看到我的幻灯片吗？

**Lance:**

可以。

**Peak:**

好的，太好了。

谢谢 Lance。今天能在这里分享一些我们从构建 Manus 中学到的关于上下文工程的最新经验教训，我感到非常兴奋。

我这里说“最新经验教训”，是因为我意识到你提到的那篇关于上下文工程的博客文章是我在 7 月份写的。是的，这是 Agent 之年，所以 7 月份基本上是上个世纪的事了。当然，在这次分享之前，我回去又读了一遍，幸运的是，我认为我在那篇博客里写的大部分内容今天仍然成立。但我不想浪费大家的时间，只是重复博客里已有的内容。所以今天，我想深入探讨一些我之前没有深入或完全没有触及的领域。实际上，我们将重点关注 Lance 刚才幻灯片里“有争议”（discourage）的那一列，因为我个人认为，探索那些非共识的想法往往能带来最大的灵感。

是的，这就是今天演讲的主题。首先，我们会谈谈一个更大的问题：为什么我们需要上下文工程。然后，我们会更多地讨论上下文精简，更多地讨论上下文隔离，最后是一些关于上下文卸载的新东西，这是我们目前在 Manus 内部正在测试的。

是的，我今天分享的所有内容都已在 Manus 的生产环境中使用，是经过实战检验的。但我不知道它们能持续多久，因为你知道，事情变化得太快了。

好的，让我们从第一个大问题开始：为什么我们甚至需要上下文工程？尤其是在今天，微调（fine-tuning）或后训练（post-training）模型已经变得容易得多。是的，例如，Thinking Machine 团队刚刚发布了 Tinker API，我非常喜欢它的设计。但对我来说，为什么需要上下文工程这个问题，实际上是经历了几个痛苦的认知阶段才得出的。

在创办 Manus 之前，我已经在自然语言处理（NLP）领域工作了超过 10 年，这基本上就是我们所说的构建语言模型，但在 ChatGPT 之前。Manus 是我的第二或第三家公司。在我之前的创业公司，我们从零开始训练自己的语言模型，用于开放域信息抽取、构建知识图谱以及在其上构建语义搜索引擎。那段经历非常痛苦。我们产品的创新速度完全被模型的迭代速度所限制。你知道，即使在当时，模型比今天的要小得多，但一个单一的“训练+评估”周期也可能需要一到两周。最糟糕的是，当时我们还没有达到产品市场契合（PMF），却把所有时间都花在提升那些对产品可能根本不重要的基准测试上。

所以我认为，初创公司真的应该尽可能长时间地依赖通用模型和上下文工程，而不是过早地构建专用模型。当然，我猜这现在已经成了一种普遍的智慧。但随着你的产品成熟和开源基础模型越来越强大，我知道你会很想去想：“嘿，也许我应该选一个强大的基础模型，用我的数据进行微调，让它在我的使用场景下表现得非常出色。”

我们也试过这样做，你猜怎么着？那是另一个陷阱。你知道，为了让 AI 真正表现出色，你通常会固定一个动作空间，围绕你当前的产品行为设计一个奖励函数，并生成大量的“在策略”（on-policy）推演和反馈。但是，这也是危险的，因为我们仍处于 AI 和 Agent 的早期阶段，一切都可能在一夜之间发生天翻地覆的变化。对我们来说，一个经典的例子是 MCP（模型创建的程序）的推出。它完全改变了 Manus 的设计，从一个紧凑的静态动作空间变成了一个可以无限扩展的东西。如果你曾经训练过自己的模型，你就会知道这种开放域问题是极难优化的。当然，你可以投入巨大的努力进行后训练以确保泛化能力，但那样一来，你不就基本上是在试图自己成为一家大语言模型公司吗？因为你基本上是在重新构建他们已经构建好的那一层，这是在重复劳动。

所以，铺垫了这么多，我的观点是：坚定地划清界限。目前，上下文工程是应用层和模型层之间最清晰、最实用的边界。所以，相信你的选择。

好了，哲学部分到此为止，我们来谈谈一些真正的技术。第一个主题，上下文精简。

在这里，我想澄清两种不同的“压缩”（compaction）操作，因为我们认为上下文精简这个概念虽然引人入胜，但也是一个新的概念，有很多方法可以实现。在 Manus，我们将其分为“压缩”（compaction）和“摘要”（summarization）。

对于“压缩”，在 Manus 中，每个工具调用和工具结果实际上都有两种不同的格式：一个完整格式和一个紧凑格式。紧凑版本会剥离任何可以从文件系统或外部状态重建的信息。例如，假设你有一个写入文件的工具，它可能有 `path` 和 `content` 两个字段。但是，一旦工具返回，你就可以确保文件已经存在于环境中。所以在紧凑格式中，我们可以安全地丢掉那个超长的 `content` 字段，只保留 `path`。如果你的 Agent 足够聪明，那么当它需要再次读取该文件时，它只需通过路径来检索即可。所以没有信息被真正丢失，它只是被“外部化”了。

我们认为这种“可逆性”至关重要，因为 Agent 确实会基于之前的动作和观察进行链式预测，你永远不知道哪个过去的动作会在 10 步之后突然变得超级重要，你无法预测。所以这是一种通过“压缩”实现的可逆的精简。

当然，“压缩”只能带你走这么远。最终，你的上下文还是会增长并触及天花板。那时，我们会将“压缩”与更传统的“摘要”结合起来，但我们做得非常小心。例如，在进行摘要之前，我们可能会将上下文的关键部分卸载到文件中。有时我们甚至做得更激进，我们可以将整个摘要前的上下文转储为一个文本文件或简单的日志文件到文件系统中，这样我们以后就总能恢复它。就像 Lance 刚才提到的，有些人只用 `glob` 和 `grep`。你知道，`glob` 对日志文件也有效。所以如果模型足够聪明，它甚至知道如何检索那些被摘要前的上下文。

是的，所以我认为这里的区别在于：“压缩”是可逆的，而“摘要”不是。两者都减少了上下文长度，但它们的行为非常不同。

为了让这两种方法共存，我们必须在顶层跟踪一些上下文长度的阈值。比如说，你的模型有一个硬性的上下文限制，比如 100 万 token，这在今天很常见。但你知道，在现实中，大多数模型在更早的时候就开始性能下降，通常在 20 万 token 左右，你会开始看到我们所说的“上下文衰减”（context rot）：重复、推理变慢、质量下降。所以，通过大量的评估，为你识别出那个“衰减前”的阈值非常重要，通常是 128k 到 200k token，并用它作为上下文精简的触发器。

每当你的上下文大小接近它时，你必须触发上下文精简，但要从“压缩”开始，而不是“摘要”。并且“压缩”并不意味着压缩整个历史记录。你知道，我们可能会压缩最旧的 50% 的工具调用，同时保持较新的调用以完整细节呈现。这样模型仍然有新鲜的、小样本（few-shot）的例子来学习如何正确使用工具。否则，在最坏的情况下，模型会模仿这种行为，输出那些带有缺失字段的紧凑格式，那将是完全错误的。

在“压缩”之后，我们必须检查我们从这个“压缩”操作中实际获得了多少空闲上下文。有时，就像这张图里显示的，经过多轮“压缩”后，收益会变得很小，因为即使是紧凑格式，它仍然占用上下文。这时，我们才会转向“摘要”。

但也要记住，在进行“摘要”时，我们总是使用数据的完整版本，而不是紧凑版本。并且我们仍然会保留最后几次工具调用和工具结果的完整细节，而不是摘要。因为这能让模型知道它上次停在哪里，并能更平滑地继续。否则你会看到，在摘要之后，模型有时会改变它的风格、改变它的语调。我们发现保留几个完整的工具调用和结果的例子非常有帮助。

好的，我们已经讨论了精简，现在让我们来谈谈隔离。

我非常同意 Cognition 在他们博客中的观点，他们警告不要使用多 Agent 配置，因为当你有多个 Agent 时，它们之间的信息同步就成了一场噩梦。但是，你知道，这不是一个新问题。多进程或多线程协调是计算机编程早期的一个经典挑战，我认为我们可以借鉴一些智慧。

我不知道今天这里有多少是 Go 语言的程序员，但在 Go 编程语言社区，有一句来自这个 Gopher 的名言：“不要通过共享内存来通信，而要通过通信来共享内存。” 当然，这不完全是关于 Agent 的，有时对 Agent 来说甚至是错误的。但我认为重要的是，它突出了两种不同的模式：“通过通信”或“通过共享内存”。

如果我们把这里的“内存”（memory）这个词翻译成“上下文”（context），我们可以看到一个非常清晰的对应关系。

“通过通信”更容易理解，因为它是经典的子 Agent 设置。例如，主 Agent 编写一个提示，这个提示被发送给一个子 Agent，而子 Agent 的整个上下文只包含那个指令。我们认为，如果一个任务有简短、清晰的指令，并且只关心最终的输出——比如说，在一个代码库中搜索一个特定的代码片段——那么就使用“通信”模式，并保持简单。因为你知道，主 Agent 不关心子 Agent 是如何找到代码的，它只需要结果。这就像 Claude Code 通常做的那样，用它的 `task` 工具来把一个独立的、清晰的任务委托给某个子 Agent。

但对于更复杂的场景，相比之下，“通过共享内存”意味着子 Agent 可以看到整个之前的上下文，也就是说，所有的工具使用历史。但是，子 Agent 有自己的系统提示（system prompt）和自己的动作空间。例如，想象一个深度研究的场景，最终的报告依赖于大量的中间搜索和笔记。在这种情况下，你应该考虑使用“共享内存”模式，或者用我们的话说，“通过共享上下文”。因为即使你可以把所有的笔记和搜索结果保存到文件中，让子 Agent 再次读取所有内容，但你只是在浪费延迟和上下文。如果你计算 token 的数量，你可能为了做这件事用了更多的 token。所以我们认为，对于那些需要完整历史的场景，就使用“共享内存”模式。但要注意，“共享上下文”是昂贵的，因为你知道，每个子 Agent 都有一个更大的输入需要预填充（prefill），这意味着你会在输入 token 上花费更多。而且由于系统提示和动作空间不同，你无法重用 KV 缓存，所以你必须支付全部费用。

最后，让我们谈谈一点关于“上下文卸载”的事情。

当人们说“卸载”时，他们通常指的是将工作上下文的一部分移动到外部文件中。但是，随着你的系统增长，特别是如果你决定有一天要集成 MCP（模型创建的程序），你会意识到工具本身也会占用大量上下文。在上下文中放置太多工具会导致混淆，我们称之为“上下文混淆”（context confusion），模型可能会调用错误的工具，甚至是根本不存在的工具。所以我们必须找到一种方法来卸载工具。

目前一个常见的方法是，对工具描述进行动态的 RAG（检索增强生成），例如，根据当前任务或当前状态按需加载工具。但这也会导致两个问题。首先，由于工具定义位于上下文的前端，你的 KV 缓存每次都会重置。最重要的是，模型过去对那些被移除的工具的调用记录仍然在上下文中，所以这可能会误导模型去调用无效的工具或使用无效的参数。

为了解决这个问题，我们正在 Manus 中试验一种新的“分层动作空间”（layered action space）。基本上，我们可以让 Manus 从三个不同层次的抽象中进行选择：
1.  **函数调用 (Function Calling)**
2.  **沙盒工具 (Sandbox Utilities)**
3.  **包和 API (Packages and API)**

我们来深入了解一下这三层分层动作空间。

让我们从第一层开始，**函数调用**。这是经典的，每个人都知道。由于约束解码（constraint decoding），它的模式（schema）是安全的。但我们都知道它的缺点，例如我们提到的会破坏缓存，以及太多的工具调用可能会导致混淆。

所以在 Manus 中，我们目前只使用固定数量的原子函数，例如：读写文件、执行 shell 命令、在文件和互联网中搜索，以及一些浏览器操作。我们认为这些原子函数有非常清晰的边界，它们可以协同工作来组合成更复杂的工作流。然后，我们把其他所有东西都卸载到下一层。

也就是**沙盒工具**。如你所知，每个 Manus 会话都在一个完整的虚拟机沙盒中运行，它运行在我们自己定制的 Linux 系统上。这意味着 Manus 可以使用 shell 命令来运行我们为 Manus 开发的预装工具。例如，我们有一些格式转换器，有语音识别工具，甚至还有一个非常特殊的，我们称之为 MCP CLI，这是我们调用 MCP 的方式。我们不把 MCP 工具注入到函数调用空间，而是通过命令行界面在沙盒内完成所有事情。

工具非常好，因为你可以添加新功能而无需触及模型的函数调用空间。你知道，这就像你电脑上预装的一些命令，如果你熟悉 Linux，你总能知道如何找到那些新命令，你甚至可以运行 `d-help` 来弄清楚如何使用一个新工具。另一个好处是，对于较大的输出，它们可以直接写入文件或分页返回结果，你可以使用所有那些 Linux 工具，如 `grep`、`cat`、`less`、`more` 来即时处理那些结果。所以这里的权衡是，它对大输出非常好，但对于与前端的低延迟来回交互就不那么好了，因为你总是需要将 Agent 的交互可视化并展示给用户。所以这里有点棘手，但我们认为它已经卸载了很多东西。

然后我们还有另一层，最后一层，我们称之为**包和 API**。在这里，Manus 可以编写 Python 脚本来调用预授权的 API 或自定义包。例如，Manus 可能会使用一个 3D 设计库来进行建模，或者调用一个金融 API 来获取市场数据。实际上，我们已经代表用户购买了所有这些 API，并为他们支付了费用，这些都包含在订阅中。所以我们基本上在 Manus 中预装了很多 API 密钥，Manus 可以使用这些密钥来访问这些 API。

我认为这些非常适合那些需要大量内存计算，但又不需要将所有数据推送到模型上下文中的任务。例如，想象一下，如果你正在分析一只股票全年的价格数据，你不会把所有数字都喂给模型，而应该让脚本去计算，然后只把摘要放回上下文中。而且你知道，由于代码和 API 是高度可组合的，你实际上可以在一步中串联很多事情。例如，在一个典型的 API 中，你可以在一个 Python 脚本中完成“获取城市名称”、“获取城市 ID”、“获取天气”所有这些操作。

还有一篇来自我一个朋友的论文，叫做《CodeAct》，很多人都在讨论它。我认为这和我们的想法是一样的，因为代码是可组合的，它可以在一步中做很多事情。但同样地，它的模式是不安全的，对代码进行约束解码非常非常困难。所以我们认为你应该为这些功能找到合适的场景。对我们来说，我们使用所有我们提到的，任何可以在编译器或解释器运行时内处理的事情，我们都用代码来做。否则，我们使用沙盒工具或函数调用。

好消息是，如果你有这三个层次，从模型的角度来看，所有三个层次仍然通过标准的函数调用来执行。所以接口保持简单、缓存友好，并且在函数之间是正交的。因为你知道，我们提到的沙盒工具，你仍然是通过 shell 工具（shell function）来访问这些工具。同样地，如果你在使用第三方应用的 API，你只是在使用文件函数（file function）来写入或读取文件，然后用 shell 函数来执行它。所以你认为这并没有给模型增加额外的开销，它仍然是模型被训练过的、已经熟悉的所有东西

**Peak:**

所以让我们放大视野，把“卸载”、“精简”、“检索”、“隔离”和“缓存”这五个维度联系起来。你会发现它们并非相互独立。我们可以看到，“卸载”和“检索”能够实现更高效的“精简”，“稳定”的“检索”使“隔离”变得安全。但是，“隔离”……哦对，“隔离”也会减慢上下文的增长速度，并降低“精简”的频率。然而，更多的“隔离”和“精简”也会影响缓存效率和输出质量。所以说到底，我认为上下文工程是一门艺术与科学，需要在多个可能相互冲突的目标之间取得完美的平衡，这真的很难。

嗯，好了，在结束之前，我想留给大家最后一个想法，它和我刚才说的所有内容都有点相反，那就是：请避免上下文过度工程（context over-engineering）。回顾 Manus 发布以来的六、七个月，我们所见过的最大的飞跃，其实并非来自添加更花哨的上下文管理层或巧妙的检索技巧，它们都来自于简化，来自于移除不必要的技巧，并更多地信任模型。每一次我们简化架构，系统都会变得更快、更稳定、更智能。因为我们认为，上下文工程的目标应该是让模型的工作更简单，而不是更难。所以，如果今天你只能带走一件事，我认为那应该是：少构建，多理解。

好的，非常感谢大家，再次感谢 Lance 和 LangChain 团队的邀请。我迫不及待地想看到你们接下来会创造出什么。现在，交还给 Lance。

**Lance:**

是的，太棒了，谢谢你的分享。嗯，我们这里有一系列很好的问题，也许我们可以开始逐一回答，如果需要的话，我们可以随时回头看幻灯片。Pete，你的幻灯片可以分享给大家吗？

**Peak:**

哦，是的，是的，我之后可以分享 PDF 版本。

**Lance:**

好的，听起来不错。嗯，好的，那我就开始看一些问题吧，也许我们可以从最新的问题开始。

嗯，第一个问题是：LLM 是如何调用各种 shell 工具的？它怎么知道有哪些工具存在，以及如何调用它们？也许你可以解释一下你在 Manus 中使用的那种多层次沙盒设置。

**Peak:**

是的。我想，你可以想象自己是一个正在使用新电脑的人。例如，如果你了解 Linux，你可以想象所有的工具都位于 `/usr/bin` 目录下。所以我们实际上做了两件事。首先，我们在系统提示中给 Manus 一个提示，告诉它：“嘿，在某个特定文件夹里有很多预装的命令行工具。” 其次，对于最常用的那些工具，我们已经把它们注入到系统提示中了，但是是以非常紧凑的方式。我们不会告诉 Agent 如何使用这些工具，我们只列出它们的名字。然后我们告诉 Agent，它可以安全地使用 `--help` 标志，因为所有的工具都是我们团队开发的，它们遵循相同的格式。

**Lance:**

明白了。那么，关于……我知道你谈了很多关于使用文件系统的内容，你对使用索引（indexing）有什么看法？如果你们处理的上下文变得足够大，你们会动态地启动向量存储（vector stores）吗？你们如何处理这个问题？

**Peak:**

是的，我认为在这个领域没有绝对的对错，就像你提到的。但在 Manus，我们不使用索引数据库，因为现在 Manus 会话中的每个沙盒都是全新的，而且用户希望能够快速地与事物互动。所以实际上我们没有时间去动态构建索引。我们更像是 Claude Code，我们依赖于 `grep` 和 `glob`。但我认为，如果你考虑构建像长期记忆这样的东西，或者如果你想集成一些企业知识库，你仍然需要依赖于外部的向量索引。因为这只关乎你能访问的信息量。但对于 Manus 来说，它是在一个沙盒中操作；对于编码 Agent 来说，它是在代码库中操作。所以这取决于规模。

**Lance:**

好的，这是一个很好的后续问题。那么，假设我是一个拥有 Manus 账户的用户，我在多个会话中与 Manus 互动。你们有“记忆”这个概念吗？比如 Claude 有 `.claude.md` 文件，它们可以在 Claude Code 的所有不同会话中持久存在。你们是怎么处理长期记忆的呢？

**Peak:**

是的。实际上，在 Manus 中我们有一个叫做“知识”（Knowledge）的概念，这有点像显式记忆。例如，你每次都可以告诉 Manus：“嘿，记住，每次我要求某个东西时，都用 Excel 格式交付给我。” 这不会自动插入到某个记忆中，而是会弹出一个对话框说：“这是我从我们之前的对话中学到的东西，你想要接受还是拒绝它？” 所以这是显式的，需要用户确认。

但同时，我们也在探索更自动化的方法。例如，Agent 中一个很有趣的事情是，与聊天机器人相比，用户更频繁地纠正 Agent。例如，Manus 常犯的一个错误是在做数据可视化时。你知道，如果你使用中文、日文或韩文，很多时候会出现字体问题，渲染出来的可视化结果会有错误。所以用户经常会说：“嘿，你应该使用 Noto Sans CJK 字体。” 对于这类事情，不同的用户会有相同的纠正。我们需要找到一种方法来利用这种集体反馈，并使用它。这有点像我们所说的“在线学习的自改进 Agent”，但是以一种无参数（parameter-free）的方式。

**Lance:**

好的。另一个不同的问题，这里有人提出，我也想了很久。你在演讲的最后提到，你们通过“移除”东西获得了很大的进步，这很可能也是因为模型本身变得越来越好，所以模型的能力在提升，你可以随着时间的推移移除一些脚手架。你是怎么看待这个问题的？因为这是我面临的最大挑战之一：随着时间的推移，模型变得更好了，我就可以移除一些东西，比如我的脚手架的某些部分。你是在一个不断上升的基础上构建，就像水位在上涨一样。你是否会每隔几个月随着新模型的发布重新审视你的架构，然后随着模型变好就删除一些东西？你是如何处理这个问题的？

**Peak:**

这是一个非常好的问题。因为你知道，实际上我们已经重构了 Manus 五次。我们是在三月份推出的 Manus，现在是十月，已经五次了。所以我们认为你不能停下来，因为模型不仅在改进，而且在改变。模型的行为会随着时间而改变。一种方法是，你可以与那些模型提供商紧密合作。但我们还有一个内部的理论，用于评估或设计我们的 Agent 架构，我之前在 Twitter 上稍微提到过。基本上，我们不关心一个静态基准测试的性能，相反，我们固定 AI Agent 的架构，然后在不同模型之间切换。如果你的架构能从一个较弱的模型切换到一个较强的模型中获得很大的提升，那么在某种程度上，你的架构就更具未来性。因为明天的弱模型可能和今天的强模型一样好。所以我们认为，在弱模型和强模型之间切换，可以给你一些关于明年会发生什么的早期信号，并给你时间来准备你的架构。

所以对于 Manus 来说，我们经常每一两个月就做一次这样的审视。我们经常在内部使用开源模型，或者可能提前接触到专有模型，来进行一些研究，以便在下一个模型发布之前就为下一个版本做好准备。

**Lance:**

是的，这是一个很好的观察。你实际上可以通过切换当今存在的不同模型来测试你的架构。是的，这非常有道理。

那么，关于存储数据的格式，有什么最佳实践或考虑吗？比如 Markdown 文件、纯文本、日志。你有什么特别偏好的吗？我想这显然是……你是怎么看待文件格式这个问题的？

**Peak:**

是的，我认为这不关乎是纯文本还是 Markdown，我们总是优先考虑基于行的格式。因为这允许模型使用像 `grep` 这样的工具，或者从一个行范围内读取。而且，Markdown 有时会带来一些麻烦。你知道，模型被训练得非常擅长使用 Markdown，有时它可能会……对于某些模型，我不想说出名字，但如果你过于频繁地使用 Markdown，它们往往会输出太多的项目符号。所以实际上，我们更倾向于使用纯文本。

**Lance:**

有道理。那么关于“压缩”（compaction）与“摘要”（summarization）的话题，让我们来谈谈“摘要”。这是一个很有趣的问题，我以前被问过很多次。你是如何写提示词来生成好的摘要的？比如，“摘要”就像你说的，是不可逆的，所以如果你没有正确地提示它，你实际上可能会丢失信息。我能想到的最好答案就是为高召回率（high recall）调整你的提示词。但你是如何处理这个问题的？对于“摘要”，你是怎么考虑提示词的？

**Peak:**

实际上，我们尝试了很多方法来优化“摘要”的提示词，但结果发现一种简单的方法效果非常好，那就是你不要使用自由形式的提示词让 AI 生成所有东西，而是可以定义一种模式（schema），它就像一个有很多字段的表单，然后让 AI 去填充它们。例如：“这是我修改过的文件”、“这是用户的目标”、“这是我上次中断的地方”。如果你使用这种更结构化的模式，至少输出会比较稳定，而且你可以在此基础上进行迭代。所以，就是不要使用自由形式的摘要。

**Lance:**

明白了。是的，这是一个很棒的观察。所以你使用结构化输出来代替自由形式的摘要，以强制某些事情总是被总结出来。是的，这非常有道理。

那么关于“压缩”（compaction）呢？我想确认一下我是否理解正确。对于“压缩”，比方说是一个搜索工具，你有一个原始的搜索工具输出，那是你的原始消息，然后“压缩”的结果就只是一个文件名之类的东西，是这样吗？

**Peak:**

是的。它不仅仅是关于工具调用，它也适用于工具的结果。你知道，有趣的是，我们发现 Manus 中几乎每一个动作都是可逆的，只要你能把它卸载到文件系统或外部状态。而对于大多数这类任务，你已经有一个唯一的标识符了。例如，对于文件操作，你当然有文件路径；对于浏览器操作，你有 URL；甚至对于搜索动作，你也有查询（query）。所以它天然地就已经存在了。

**Lance:**

这太棒了，我想再强调一遍，因为我经常遇到这个问题。例如，我是一个使用搜索的 Agent，我执行搜索，它返回了一个高 token 消耗的工具调用。我不想把整个工具消息返回给 Agent。我尝试过做一些“摘要”或“压缩”，然后把摘要发回去。但你是怎么处理的？因为你可能希望 Agent 能够访问所有这些信息来做下一步决策，但你又不想那个巨大的上下文块一直存在于你的消息历史中。你是怎么处理这个问题的？你可以把整个消息发回去，但稍后再删除它——这正是 Claude 现在做的。你可以先做一个“摘要”，然后把摘要发过去。你可以把所有东西都发过去，然后再做“压缩”，这样以后你的消息历史中就不会有完整的上下文，只有一个指向文件的链接。你是怎么看待这个具体问题的，你明白我的意思吗？

**Peak:**

我明白。实际上，这取决于场景。例如，对于复杂的搜索——我说的复杂搜索是指，它不只是一个查询，比如你有多个查询，并且你想收集一些重要的东西，丢掉其他所有东西。在这种情况下，我认为我们应该使用子 Agent，或者在我们内部称之为“Agent 即工具”（agent as tool）。所以从模型的角度来看，它仍然是一种函数，可能叫做 `advanced_search`（高级搜索）。这是一个叫做 `advanced_search` 的函数，但它实际触发的是另一个子 Agent。但那个子 Agent 更像是一个工作流或一个 Agentic 工作流，它有一个固定的输出模式（schema），那个结果会返回给主 Agent。

但对于其他更简单的搜索，例如只是搜索谷歌，我们就使用完整细节的格式，然后把它追加到上下文中，并依赖于“压缩”机制。但同时，我们也总是指示模型把中间的见解或关键发现写入文件，以防“压缩”发生得比模型预期的要早。如果你把这个做得非常好，实际上通过“压缩”你不会丢失太多信息。因为有时那些旧的工具调用随着时间的推移就变得无关紧要了。

**Lance:**

有道理。我喜欢“Agent 即工具”这个想法，我们也经常这样做，这确实非常有效。但这又引出了另一个有趣的点，你也稍微提到了，就是 Agent 之间的通信。你是如何解决这个问题的？Cognition 的 Walden Yan 在一篇非常好的博客文章中谈到，这是他们在使用 Devin 时遇到的一个主要问题。所以，Agent 之间的通信，你是如何看待这个问题的？如何确保传输了足够的信息，但又不会像你说的，用太多上下文来预填充子 Agent？

**Peak:**

是的。你知道，我们在 Manus 一个月前推出了一个叫做“Wide Research”的功能，它基本上是我们所说的“Agentic MapReduce”，因为我们受到了 MapReduce 设计的启发。这对 Manus 来说很特别，因为会话背后有一个完整的虚拟机。所以我们传递信息或上下文的一种方式，就是通过共享同一个沙盒。文件系统就在那里，你只需要传递不同的路径就行了。

我认为，向子 Agent 发送信息并不难，更复杂的是如何从不同的 Agent 那里获得正确的输出。我们在这里做了一个技巧：每当主 Agent 想要生成一个新的子 Agent，或者可能是 10 个子 Agent 时，你必须让主 Agent 来定义输出模式（schema）。而在子 Agent 的视角，你有一个特殊的工具叫做 `submit_result`（提交结果），我们使用约束解码来确保子 Agent 提交回主 Agent 的内容符合主 Agent 定义的模式。是的，所以你可以想象，这种 MapReduce 操作会生成一种类似电子表格的东西，而这个电子表格是由那个模式约束的。

**Lance:**

这是一个似乎在你设计 Manus 时经常出现的主题：你使用模式（schema）和结构化输出来进行“摘要”和 Agent 间的通信。这就像是使用模式作为契约，在 Agent 和子 Agent 之间，或者在工具和你的 Agent 之间，以确保以结构化、完整的方式传递足够的信息。比如，你在做“摘要”时也使用模式。好的，太棒了，这非常非常有帮助。

我正在看一些其他有趣的问题。你们对像……我想你们用的是 Anthropic 的模型，但你们会使用开源模型吗？你们会做微调吗？你谈了很多关于使用 KV 缓存的事情，所以为此可能会使用开源模型。你对模型的选择是怎么看的？

**Peak:**

实际上，我们目前不使用任何开源模型。我认为这不关乎质量，有趣的是，这关乎成本。你知道，我们经常认为开源模型可以降低成本，但如果你处于 Manus 这样的规模，并且你在构建一个真正的 Agent，其输入远长于输出，那么 KV 缓存就变得超级重要。而如果你使用开源解决方案，分布式 KV 缓存是很难实现的。而如果你使用那些前沿的大语言模型提供商，他们在全球范围内部署了更坚实的分布式缓存基础设施。所以有时，如果你算一下，至少对 Manus 来说，我们发现使用这些旗舰模型有时甚至比使用开源模型更便宜。

而且我们现在不仅使用 Anthropic 的模型。Anthropic 的模型对于 Agentic 任务是最佳选择，但我们也看到了 Gemini 和 OpenAI 新模型的进展。我认为现在这些前沿实验室的方向并没有趋同。例如，如果你在做编码，当然应该用 Claude。如果你想做更多多模态的事情，你应该用 Gemini。而 OpenAI 的模型在复杂的数学和推理方面非常出色。所以我认为，像我们这样的应用公司，我们的一个优势是我们不必只依赖于一个模型。你可以做一些任务级别的路由，甚至可能是子任务或步骤级别的路由，如果你能引入那种 KV 缓存验证的话。所以我认为这对我们来说是一个优势，我们在内部做了大量的评估，以了解在哪个子任务上使用哪个模型。

**Lance:**

是的，这非常有道理。我想澄清一个小问题。关于 KV 缓存，你具体使用了提供商的哪些功能来进行缓存管理？我知道比如 Anthropic 有输入缓存（input caching）的例子。

**Peak:**

是的，那就是你说的意思。

**Lance:**

明白了。好的，太好了。

嗯，我正在看其他一些问题。对了，工具选择（tool selection）是个好问题。你刚才说你们不使用像对工具描述进行索引，然后根据语义相似度动态获取工具的方法。你们是怎么处理的？多少个工具算是太多了？工具选择是个经典问题，你怎么看？

**Peak:**

是的。首先，这取决于模型，不同的模型对工具的容量不同。但我认为一个经验法则是，尽量不要包含超过 30 个工具。这只是我脑海中的一个随便的数字，但实际上我认为，如果你在构建一个我们称之为“通用 AI Agent”的东西，比如 Manus，你会想确保那些原生函数是高度原子化的。所以实际上，我们需要放入动作空间的原子函数并没有那么多。比如 Manus，我们现在只有大约 10 到 20 个原子函数，其他所有东西都在沙盒里。所以我们不必动态地拉取东西。

**Lance:**

好观点。我们来更详细地解释一下。所以你有，比如说 10 个工具可以被 Agent 直接调用。但然后，就像你说的，Agent 也可以选择，比如说，写一个脚本，然后执行这个脚本。这极大地扩展了它的动作空间，而无需给它为每个可能的脚本都提供一个独立的工具——那当然是疯了。所以一个非常通用的工具，比如“写一个脚本然后运行它”，就做了很多工作。你是这个意思吗？

**Peak:**

是的，完全正确。因为你知道，为什么我们非常有信心称 Manus 为通用 Agent？因为它运行在一台计算机上，而计算机是图灵完备的。计算机是人类最伟大的发明。理论上，一个 Agent 可以做任何一个初级实习生能用电脑做的事情。所以有了 shell 工具和文本编辑器，我们认为它已经是完备的了。所以你可以把很多东西卸载到沙盒里。

**Lance:**

好的，这非常有道理。那么 Manus 是如何……所以所有的，好吧，我退一步说。你提到了 CodeAct 和编码 Agent。我的理解是，模型实际上总是会生成一个脚本，然后在代码沙盒中运行。所以每一次工具调用实际上都是生成并运行一个脚本。听起来你们做的是一种混合方法，有时 Manus 可以直接调用工具，但其他时候它实际上可以选择在沙盒中做一些事情，对吗？所以这是一种混合方法。

**Peak:**

是的。我认为这一点超级重要。因为实际上我们尝试过完全使用 CodeAct 的方式来构建 Manus，但问题是如果你使用代码，你就无法利用约束解码，事情可能会出错。但是，你知道，CodeAct 有一些特殊的用例，就像我之前在幻灯片中提到的，例如处理大量数据。你不必把所有东西都放到工具结果里，而是把它放到比如 Python 的运行时内存中，然后只把结果返回给模型。所以我们认为你应该以一种混合的方式来做。

**Lance:**

明白了。允许工具调用，你有大约 10 个左右的工具可以直接调用，还有一些工具实际上在沙盒本身运行。太好了，这非常有道理，非常有趣。

那么，你是如何保留所有之前生成的……我想你有……所以你基本上会生成一堆文件。哦，对不起，也许我该谈谈别的话题。规划（planning）怎么样？跟我谈谈规划，我知道 Manus 有那个 to-do 工具，或者说它会在任务开始时生成一个待办事项列表。跟我谈谈那个。

**Peak:**

我觉得这很有趣。因为在最开始，Manus 使用 `todo.md` 那个范式。我不想用“愚蠢”这个词，但它实际上浪费了大量的交互轮次（turn）。你知道，在大概三月或四月的时候，如果你检查一些 Manus 任务的日志，可能三分之一的动作都是关于更新待办事项列表的，这浪费了大量的 token。所以现在我们使用一种更结构化的规划。例如，如果你使用 Manus，在系统底部有一个规划器（planner）。在内部，它也是一种工具调用，我们是用“Agent 即工具”的范式实现的。所以有一个独立的 Agent 在管理这个计划。所以实际上，最新版本的 Manus 我们不再使用那个 `todo.md` 的东西了。当然，`todo.md` 仍然有效，也能生成好的结果，但如果你想节省 token，你可以找到另一种方法。

**Lance:**

明白了。所以你有一个规划器 Agent，对于一个子任务，它更像是“Agent 即工具”调用那样的东西。是的，明白了。而且你知道，有一个独立的、拥有不同视角的 Agent 来做一些外部审查是非常重要的，你还可以为规划使用不同的模型。例如，哦对，有时 Claude 3 Haiku 能产生一些非常有趣的见解。

**Lance:**

那真是个好话题。那么，考虑一下多 Agent，你是怎么想的？你可能有一个规划器 Agent，它有自己的上下文窗口，它制定一个计划，生成某种计划对象，可能是一个文件，也可能它直接调用子 Agent。你是怎么看待这个的？你通常推荐使用多少个不同的子 Agent？

**Peak:**

我想这也取决于你的设计。但在 Manus，实际上 Manus 不像是典型的多 Agent 系统。例如，我们见过很多按角色划分的不同 Agent，比如你有一个设计师 Agent，或者一个程序员 Agent，一个经理 Agent。我们不这样做，因为我们认为，我们之所以有这种划分，是因为人类公司就是这么运作的，这是由于人类上下文的限制。在 Manus，Manus 是一个多 Agent 系统，但我们不按角色划分。我们只有很少的 Agent。例如，我们有一个巨大的通用执行器 Agent，一个规划器 Agent，一个知识管理 Agent，可能还有一些……数据 API 注册 Agent。是的，我们对于增加更多的子 Agent 非常非常谨慎，原因我们之前提过：通信非常困难。我们更多地是把子 Agent 实现为“Agent 即工具”的形式，就像我们之前提到的。

**Lance:**

是的，这是一个很好的观点。我经常看到这个错误，或者说我不知道这算不算错误，但你经常看到人们把 Agent 拟人化，比如“这是我的设计师 Agent”。我觉得把 Agent 想象成一个人类组织结构图是一种牵强的类比。明白了。所以对你来说，就像一个规划器和一个知识管理器。一个知识管理器可能会做什么？比如，它的任务会是什么？

**Peak:**

它甚至比我们提到的更简单。我们在 Manus 有一个知识系统。知识 Agent 做的事情就是，它回顾用户和 Agent 之间的对话，然后找出哪些内容应该被保存在长期记忆中。就这么简单。

**Lance:**

明白了。好的，明白了。就像一个内存管理器、一个规划器，然后你有子 Agent，它们可以承担像通用执行器这样的角色，可以调用沙盒里的所有工具或动作。这很有道理，保持简单，我非常喜欢这一点。是的，这非常有道理。

嗯，让我看看这里还有没有……这里有一堆问题，但我们已经谈了很多了。所以实际上……

关于安全护栏（guardrailing）怎么样？有人问了一个关于安全和护栏的问题。你是怎么看待这个的？我想沙盒的一个好处就是这个，但请跟我谈谈你是怎么想的。

**Peak:**

是的，我想这是一个非常敏感的问题。因为你知道，如果你有一个连接到互联网的沙盒，任何事情都是危险的。所以我们在安全护栏方面投入了大量的努力。至少我们不让信息离开沙盒。例如，如果你被提示注入（prompt injected），我们对出站流量有一些检查。例如，我们会确保没有像 token 这样的东西会离开沙盒。如果用户想从沙盒中打印一些东西，我们有那种……我们称之为“移除”（removing）东西的机制，以确保没有信息流出沙盒。

但是，你知道，还有另一种情况。我们在 Manus 内部有一个浏览器，而浏览器非常复杂。例如，如果你登录到某些网站，你可以选择让 Manus 持久化你的登录状态。这被证明非常棘手，因为有时网页的内容也可能是恶意的，也许他们在做提示注入。我认为这在某种程度上超出了应用公司的范围。所以我们正在与那些计算机使用模型（computer-use model）提供商，比如 Anthropic 和 Google，紧密合作。他们正在增加大量的安全护栏。

所以现在在 Manus 中，每当你做一些敏感操作，无论是在浏览器内还是在沙盒内，Manus 都会要求你手动确认。你必须接受它，否则你必须自己接管来完成它。所以我认为，对我们来说，设计一个像……一个非常完善的解决方案是相当困难的，但这是一个渐进的方法。所以现在我们让用户更频繁地接管，但如果模型本身的安全护栏变得更好，我们就可以做得更少。

**Lance:**

关于评估（evals）的话题怎么样？这在网上被讨论了很多。你可能已经看到，比如 Claude Code，他们谈了很多关于只做较少正式评估的事情，至少对于代码来说是这样，因为代码评估或多或少已经饱和了，他们做了大量的内部“吃狗粮”（dogfooding）。你是怎么看待评估的？它们有用吗？哪些评估是真正有用的？你的方法是什么？

**Peak:**

是的。你知道，在最开始，在 Manus 刚推出时，我们使用的是像 GAIA 这样的公共学术基准测试。但后来，向公众推出后，我们发现这非常不一致。你知道，那些在 GAIA 上得分高的模型，用户并不喜欢。所以现在我们使用三种不同的评估。首先，最重要的是，对于 Manus 中每一个完成的会话，我们都会请求用户给一个反馈，打一到五颗星。这是黄金标准，我们总是关心平均用户评分，这是第一点。

第二点，我们仍然使用一些带有可验证结果的内部自动化测试。例如，我们创建了我们自己的、有明确答案的数据集。但同时，是的，我们仍然使用大量的公共学术基准测试，但我们也创建了一些更侧重于执行的数据集。因为大多数现有的基准测试更侧重于只读任务，所以我们设计了一些执行任务或事务性任务。因为我们有沙盒，我们可以频繁地重置测试环境。这些是自动化的部分。

最重要的是第三点，我们有很多实习生。你知道，你必须使用大量真正的实习生来做像网站生成或数据可视化这样的评估。因为很难设计一个好的奖励模型，它知道输出在视觉上是否吸引人，这关乎品味。所以我们仍然依赖大量的……大量的真人评估。

**Lance:**

太好了。我知道我们快到时间了，但我想问你关于这个新兴趋势的问题：使用可验证奖励的强化学习（reinforcement learning with verifiable rewards） vs 仅仅构建工具调用 Agent。比如，Claude Code 非常出色，他们有优势，因为他们构建了那个工具套件（harness），他们可以在自己的工具套件上进行强化学习，并且在使用他们提供的工具时可以变得非常非常出色。你们做强化学习吗？或者你怎么看待这个问题？因为当然，在这种情况下，你可能会使用开源模型。我最近一直在玩这个。你怎么看，就是直接使用模型提供商的开箱即用的工具调用，还是在你的环境中用你的工具套件自己做强化学习？

**Peak:**

我提过，在创办 Manus 之前，我算是做模型训练的，我做过很多年的预训练、后训练、强化学习。但我必须说，现在，如果你有足够的资源，你可以尝试。但实际上，就像我之前提到的，MCP 是一个巨大的改变者。因为如果你想支持 MCP，你使用的就不是一个固定的动作空间。如果不是固定的动作空间，就非常非常难设计一个好的奖励函数，而且你无法生成大量的……推演和反馈会变得不平衡。所以如果你想构建一个支持 MCP 的模型，你实际上是在自己构建一个基础模型。

所以我认为，社区里的每个人，像模型公司，他们都在做同样的事情，他们正在为你做同样的事情。所以我认为我们现在不应该花那么多时间去做强化学习。但就像我之前提到的，我们正在探索新的方法来做，也许可以称之为“个性化”或某种形式的在线学习，但是使用无参数的方式，例如集体反馈。

**Lance:**

沿着这个思路，有一个小问题。比如说，Anthropic 在 Claude Code 上对一组工具使用了带可验证奖励的强化学习。你有没有发现，你可以通过模仿你的工具套件，使用相似的工具名称来解锁同样的能力？你明白我的意思吗？比如，我相信他们显然做了……他们使用了 `glob`、使用了 `grep`、还有一些其他用于操纵文件系统的工具。你能在你的工具套件中通过拥有完全相同的工具、相同的工具名称、相同的描述来有效地复制同样的功能吗？或者你怎么看待这个问题，就是解锁……是的，你明白我的意思。

**Peak:**

是的。我明白这里的明确答案，但对我们来说，我们实际上尽量不使用相同的名字。因为如果你设计自己的函数，你可能对那个函数有不同的要求，参数、输入参数可能都不同。所以你不想让模型感到困惑，如果模型被训练了大量包含某些内部工具的后训练数据，你不想让模型感到困惑。

**Lance:**

好的，明白了。明白了。太好了。

我想我们实际上到时间了，我想尊重你的时间，因为我知道你那里很早，你在新加坡，对你来说时间非常早。所以……

嗯，这次分享真的太棒了，谢谢你。我们一定会确保这次的录像可用，也会确保幻灯片可用。你还有什么临别赠言、想强调的事情，或者想号召大家做什么吗？

**Peak:**

是的，大家应该去试试 Manus，我们有免费版。

**Lance:**

是的，当然。嘿，非常感谢 Pete，希望以后还有机会再做一次。

**Peak:**

是的，谢谢你的邀请。

**Lance:**

好的，再见。

**Peak:**

再见。