---
title: "上下文工程：Agent系统设计的核心方法论"
date: "2026-02-25"
tags: ["Agent", "Context Engineering", "Architecture"]
excerpt: "上下文工程 ≠ 提示工程。本文系统性地讲解Agent系统设计中的核心方法论，从上下文组成、退化模式、压缩优化，到多智能体架构、记忆系统、工具设计和项目开发流程。"
---

# 上下文工程：Agent系统设计的核心方法论

## 引言

在大模型应用的开发实践中，我们经常面临一个根本性约束：**上下文窗口是有限的**。

当Agent系统的对话轮次增加、检索文档累积、工具输出膨胀，上下文很快就会达到极限。此时，系统性能开始退化——Agent"遗忘"之前的决策，推理质量下降，甚至产生幻觉。

**上下文工程**（Context Engineering）正是解决这一问题的方法论体系。它不等同于提示工程（Prompt Engineering），而是关注进入模型的所有信息的管理与优化。

![上下文工程核心架构](/MyBlog/images/agent-context-engineering/architecture.png)

本文基于开源项目 [Agent-Skills-for-Context-Engineering](https://github.com/anthropics/agent-skills) 的源代码分析，系统性地讲解Agent系统设计的核心方法论。

---

## 第一部分：上下文基础

### 1.1 上下文的解剖学

上下文是大模型在推理时可用的**完整状态**，包含五个核心组成部分：

| 组成部分 | 说明 | Token占比 |
|---------|------|----------|
| **系统提示** | Agent的身份、约束和行为指南 | 固定 |
| **工具定义** | Agent可采取的行动（名称、描述、参数） | 中等 |
| **检索文档** | 通过RAG获取的领域知识 | 可变 |
| **消息历史** | 用户与Agent的对话、推理轨迹 | 持续增长 |
| **工具输出** | 文件内容、搜索结果、API响应 | **83.9%** |

研究数据显示，在典型的Agent轨迹中，工具输出（observations）占据了总token使用的绝大多数。这是上下文管理的关键瓶颈。

**系统提示的设计原则**：

系统提示应采用"正确高度"的描述风格。过于复杂的硬编码逻辑会导致脆弱性，而过于模糊的高层指导则无法给出具体信号。

```markdown
<BACKGROUND_INFORMATION>
你是一个Python专家，正在帮助开发团队进行数据处理。
当前项目：Python 3.9+ 数据处理管道
</BACKGROUND_INFORMATION>

<INSTRUCTIONS>
- 编写符合Python习惯的代码
- 为函数签名添加类型提示
- 为公共函数添加文档字符串
- 遵循PEP 8代码风格
</INSTRUCTIONS>

<TOOL_GUIDANCE>
使用bash执行shell操作，使用python执行代码任务。
文件操作应使用pathlib以确保跨平台兼容性。
</TOOL_GUIDANCE>

<OUTPUT_DESCRIPTION>
提供带语法高亮的代码块。
用注释解释非显而易见的决策。
</OUTPUT_DESCRIPTION>
```

### 1.2 注意力预算约束

Transformer模型的注意力机制为所有token对创建关系，计算复杂度为O(n²)。随着上下文长度增加，模型捕获关系的能力被稀释。

**关键发现**：
- 模型在训练数据中主要看到的是短序列
- 位置编码插值虽然支持更长序列，但会降低位置精度
- 上下文质量比数量更重要

### 1.3 渐进式披露原则

**核心思想**：仅在需要时加载信息。

实现方式：系统启动时只加载技能名称和描述，完整内容在技能激活时才加载。这保持了Agent的响应速度，同时提供了按需访问更多上下文的能力。

```python
# 静态上下文（始终加载）
AVAILABLE_SKILLS = """
- database-optimization: 查询调优和索引策略
- api-design: REST/GraphQL最佳实践
- testing-strategies: 单元测试、集成测试和端到端测试模式
"""

# 动态上下文（按需加载）
def load_skill(skill_name):
    return read_file(f"skills/{skill_name}/SKILL.md")
```

### 1.4 上下文质量 vs 数量

一个被证伪的假设：更大的上下文窗口可以解决记忆问题。

**实际情况**：
- 处理成本随长度非线性增长
- 超过一定长度后性能下降
- 长输入即使有前缀缓存也很昂贵

**指导原则**：信息性 > 穷尽性。包含与当前决策相关的内容，排除不相关的内容，并设计能够按需访问额外信息的系统。

---

## 第二部分：上下文退化模式

![上下文退化模式](/MyBlog/images/agent-context-engineering/degradation.png)

### 2.1 Lost-in-Middle现象

这是最著名的退化模式：模型呈现**U型注意力曲线**，上下文开头和结尾的信息能够可靠召回，而中间信息的召回准确率显著降低10-40%。

**原因**：
- 模型为第一个token（通常是BOS token）分配大量注意力以稳定内部状态
- 有限的注意力预算被拉伸，中间token无法获得足够的权重

**缓解策略**：
1. 将关键信息放在上下文的开头或结尾
2. 使用摘要结构将关键信息提取到注意力优势位置
3. 使用明确的章节标题和过渡帮助模型导航结构

### 2.2 上下文中毒

当幻觉、错误或错误信息进入上下文并通过重复引用而复合时，就会发生上下文中毒。一旦中毒，上下文会产生反馈循环，强化错误信念。

**中毒入口**：
1. 工具输出包含错误或意外格式
2. 检索文档包含错误或过时信息
3. 模型生成的摘要或中间输出引入幻觉

**检测与恢复**：
- 监控输出质量下降、工具错误增加、持续存在的幻觉
- 恢复方法：截断上下文到中毒点之前，或在上下文中明确标记中毒并请求重新评估

### 2.3 上下文分心

当上下文过长导致模型过度关注提供的信息而牺牲训练知识时，就会发生上下文分心。

**研究发现**：即使只有一个不相关的文档，也会降低涉及相关文档的任务性能。

**缓解策略**：
- 在加载检索文档之前应用相关性过滤
- 使用命名空间和组织使不相关的部分在结构上易于忽略
- 考虑信息是否真的需要在上下文中，还是可以通过工具调用来访问

### 2.4 四桶策略

针对上下文退化，有四种核心策略：

| 策略 | 描述 | 适用场景 |
|-----|------|----------|
| **Write** | 将上下文存储在上下文窗口外部 | 长期信息保留 |
| **Select** | 通过检索、过滤和优先级将相关上下文拉入窗口 | 减少分心 |
| **Compress** | 通过摘要、抽象和观察掩码减少token | 扩展有效容量 |
| **Isolate** | 将上下文分割到子Agent或会话中 | 防止单一上下文过大 |

**架构实现**：
- **Write**：使用便签本、文件系统或外部存储
- **Select**：RAG检索、相关性过滤
- **Compress**：结构化摘要、观察掩码
- **Isolate**：子Agent架构、会话分割

---

## 第三部分：上下文压缩

### 3.1 优化目标：Tokens-per-Task

传统压缩指标优化的是 **tokens-per-request**，这是错误的优化目标。

当压缩丢失关键细节（如文件路径或错误消息）时，Agent必须重新获取信息、重新探索方法，浪费token恢复上下文。

**正确的指标**：**tokens-per-task** — 从任务开始到完成消耗的总token数。

### 3.2 锚定迭代摘要

三种生产就绪的压缩方法：

| 方法 | 压缩率 | 质量评分 | 特点 |
|-----|-------|---------|-----|
| 锚定迭代摘要 | 98.6% | 3.70 | 最佳质量，结构化强制保留 |
| 再生式摘要 | 98.7% | 3.44 | 良好质量，完整重新生成 |
| 不透明压缩 | 99.3% | 3.35 | 最佳压缩，质量损失 |

**核心洞察**：结构强制保留。专用部分充当检查清单，防止静默信息漂移。

**结构化摘要模板**：

```markdown
## 会话意图
[用户试图完成的内容]

## 修改的文件
- auth.controller.ts: 修复JWT令牌生成
- config/redis.ts: 更新连接池配置
- tests/auth.test.ts: 添加新配置的mock设置

## 决策记录
- 使用Redis连接池而非每请求连接
- 对瞬态故障使用指数退避重试逻辑

## 当前状态
- 14个测试通过，2个失败
- 待完成：会话服务测试的mock设置

## 下一步
1. 修复剩余的测试失败
2. 运行完整测试套件
3. 更新文档
```

### 3.3 工件追踪问题

这是所有压缩方法中最弱的维度，评分仅为2.2-2.5/5.0。

编码Agent需要追踪：
- 创建了哪些文件
- 修改了哪些文件以及修改了什么
- 读取但未更改的文件
- 函数名、变量名、错误消息

**解决方案**：可能需要专门的工件索引或Agent脚手架中的显式文件状态追踪。

### 3.4 压缩触发策略

| 策略 | 触发点 | 权衡 |
|-----|-------|-----|
| 固定阈值 | 70-80%上下文利用率 | 简单但可能过早压缩 |
| 滑动窗口 | 保留最近N轮 + 摘要 | 可预测的上下文大小 |
| 重要性导向 | 先压缩低相关性部分 | 复杂但保留信号 |
| 任务边界 | 在逻辑任务完成时压缩 | 摘要清晰但时机不可预测 |

---

## 第四部分：上下文优化技术

### 4.1 压缩策略

**压缩实现**：识别可压缩的部分，生成捕获要点的摘要，用摘要替换完整内容。

**压缩优先级**：
1. 工具输出 → 用摘要替换
2. 旧对话 → 摘要早期对话
3. 检索文档 → 如有新版本则摘要
4. **永不压缩**系统提示

### 4.2 观察掩码

工具输出可占Agent轨迹中token使用的80%以上。观察掩码用紧凑引用替换冗长的工具输出。

**掩码策略选择**：

| 永不掩码 | 考虑掩码 | 始终掩码 |
|---------|---------|---------|
| 当前任务关键的观察 | 3轮以上前的观察 | 重复输出 |
| 最近一轮的观察 | 可提取要点的冗长输出 | 已经在对话中摘要的输出 |
| 活跃推理中使用的观察 | 已服务目的的观察 | 样板页眉/页脚 |

**实现示例**：

```python
def mask_observation(observation: str, max_length: int = 2000) -> str:
    if len(observation) < max_length:
        return observation

    # 存储完整观察
    ref_id = store_observation(observation)

    # 返回引用
    key_summary = extract_key_points(observation, max_tokens=200)
    return f"[观察:{ref_id}已省略。关键点:{key_summary}]"
```

### 4.3 KV缓存优化

KV缓存存储推理期间计算的Key和Value张量，随序列长度线性增长。

**前缀缓存**：使用基于哈希的块匹配重用具有相同前缀的请求中的KV块。

**缓存友好模式**：
```python
# 稳定内容优先
context = [
    system_prompt,      # 可缓存
    tool_definitions,   # 可缓存
    reused_templates,   # 可重用
    unique_content,     # 唯一
]
```

**缓存优化设计**：
- 避免动态内容如时间戳
- 使用一致的格式
- 在会话间保持结构稳定

### 4.4 上下文分区

最激进的上下文优化形式是将工作跨具有隔离上下文的子Agent分区。

每个子Agent在专注于其子任务的干净上下文中操作，而不携带来自其他子任务的累积上下文。

**结果聚合**：
1. 验证所有分区完成
2. 合并兼容结果
3. 如仍然过大则摘要

---

## 第五部分：多智能体架构模式

![多智能体架构模式](/MyBlog/images/agent-context-engineering/multi-agent.png)

### 5.1 为什么需要多Agent

**上下文瓶颈**：单一Agent面临推理能力、上下文管理和工具协调的固有限制。

**Token经济学现实**：多Agent系统消耗的token显著更多。

| 架构 | Token倍数 | 用例 |
|-----|----------|-----|
| 单Agent聊天 | 1× 基准 | 简单查询 |
| 单Agent + 工具 | ~4× 基准 | 工具使用任务 |
| 多Agent系统 | ~15× 基准 | 复杂研究/协调 |

**BrowseComp评估发现**：三个因素解释了95%的性能方差：
1. Token使用（80%的方差）
2. 工具调用数量
3. 模型选择

**关键洞察**：升级到更好的模型往往比加倍token预算提供更大的性能提升。

### 5.2 监督者/编排者模式

```
用户查询 → 监督者 → [专家, 专家, 专家] → 聚合 → 最终输出
```

**适用场景**：
- 具有明显分解的复杂任务
- 需要跨域协调的任务
- 人工监督重要的任务

**优势**：严格控制工作流程、易于实现人工干预、确保遵循预定义计划。

**劣势**：监督者上下文成为瓶颈、监督者失败级联到所有工作者、"传声筒"问题。

**"传声筒"问题**：LangGraph基准测试发现，由于监督者错误地转述子Agent响应，监督者架构最初性能比优化版本低50%。

**解决方案**：实现`forward_message`工具：
```python
def forward_message(message: str, to_user: bool = True):
    """
    将子Agent响应直接转发给用户，无需监督者综合。

    使用场景：
    - 子Agent响应是最终且完整的
    - 监督者综合会丢失重要细节
    - 响应格式必须完全保留
    """
    if to_user:
        return {"type": "direct_response", "content": message}
    return {"type": "supervisor_input", "content": message}
```

### 5.3 对等/群体模式

去除中央控制，允许Agent基于预定义协议直接通信。

```python
def transfer_to_agent_b():
    return agent_b  # 通过函数返回转移

agent_a = Agent(
    name="Agent A",
    functions=[transfer_to_agent_b]
)
```

**适用场景**：需要灵活探索的任务、刚性规划适得其反的任务、具有突发需求的任务。

**优势**：无单点故障、有效扩展广度优先探索、支持突发问题解决行为。

**劣势**：协调复杂度随Agent数量增加、无中央状态保持者时有偏离风险、需要强大的收敛约束。

### 5.4 层次化模式

```
战略层（目标定义）→ 规划层（任务分解）→ 执行层（原子任务）
```

**适用场景**：具有清晰层次结构的大型项目、具有管理层的企业工作流、需要高层规划和详细执行的任务。

### 5.5 上下文隔离作为设计原则

多Agent架构的主要目的是**上下文隔离**。

**隔离机制**：

| 机制 | 描述 | 权衡 |
|-----|------|-----|
| 全量上下文委托 | 子Agent接收完整上下文 | 最大能力但违背子Agent目的 |
| 指令传递 | 子Agent仅接收指令 | 保持隔离但限制灵活性 |
| 文件系统记忆 | Agent读写持久存储 | 共享状态但引入延迟 |

**选择依据**：任务复杂度、协调需求、可接受的延迟。

### 5.6 共识与协调

**投票问题**：简单多数投票将弱模型的幻觉视为与强模型推理等同。

**解决方案**：
1. **加权投票**：按置信度或专业知识加权
2. **辩论协议**：要求Agent在多轮中批评彼此的输出
3. **触发式干预**：监控停滞和谄媚触发器

---

## 第六部分：记忆系统设计

![记忆系统架构](/MyBlog/images/agent-context-engineering/memory.png)

### 6.1 生产框架对比

| 框架 | 架构 | 最适场景 | 权衡 |
|-----|------|---------|-----|
| **Mem0** | 向量存储 + 图记忆 | 多租户系统、广泛集成 | 多Agent专门化较弱 |
| **Zep/Graphiti** | 时序知识图谱、双时态模型 | 需要关系建模+时序推理的企业级 | 高级功能云端锁定 |
| **Letta** | 自编辑记忆、分层存储 | 完全Agent内省、有状态服务 | 简单用例复杂度高 |
| **LangMem** | LangGraph工作流记忆工具 | LangGraph团队 | 强耦合到LangGraph |
| **文件系统** | 带命名约定的普通文件 | 简单Agent、原型设计 | 无语义搜索、无关系 |

**基准性能对比**：

| 系统 | DMR准确率 | LoCoMo | 延迟 |
|-----|----------|--------|-----|
| Zep（时序KG） | 94.8% | — | 2.58s |
| Letta（文件系统） | — | 74.0% | — |
| Mem0 | — | 68.5% | — |
| 向量RAG基线 | ~60-70% | — | 快 |

**关键洞察**：Letta基于文件系统的Agent在LoCoMo上达到74%，使用基本文件操作，优于Mem0的专用工具——**工具复杂性不如可靠检索重要**。

### 6.2 记忆层级决策

| 层级 | 持久性 | 实现 | 何时使用 |
|-----|-------|------|---------|
| **工作记忆** | 仅上下文窗口 | 系统提示中的便签本 | 始终—用注意力优势位置优化 |
| **短期记忆** | 会话范围 | 文件系统、内存缓存 | 中间工具结果、对话状态 |
| **长期记忆** | 跨会话 | 键值存储 → 图DB | 用户偏好、领域知识 |
| **实体记忆** | 跨会话 | 实体注册表 + 属性 | 维护身份（跨对话的同一人） |
| **时序KG** | 跨会话 + 历史 | 带有效性区间的图 | 随时间变化的事实、时间旅行查询 |

**渐进式策略**：从简单开始，仅在检索失败时增加复杂性。

1. **原型**：文件系统记忆。存储为带时间戳的结构化JSON。
2. **扩展**：Mem0或向量存储+元数据，用于语义搜索和多租户隔离。
3. **复杂推理**：Zep/Graphiti，用于关系遍历、时序有效性。
4. **完全控制**：Letta，用于深度内省的Agent自我记忆管理。

### 6.3 检索策略

| 策略 | 使用场景 | 局限 |
|-----|---------|-----|
| **语义**（嵌入相似度） | 直接事实查询 | 多跳推理时退化 |
| **实体**（图遍历） | "告诉我关于X的一切" | 需要图结构 |
| **时序**（有效性过滤） | 事实随时间变化 | 需要有效性元数据 |
| **混合**（语义+关键词+图） | 最佳整体准确率 | 最多基础设施 |

**Zep的混合方法**：通过仅检索相关子图实现90%延迟减少（2.58s vs 28.9s）。

---

## 第七部分：工具设计原则

![工具设计原则](/MyBlog/images/agent-context-engineering/tool-design.png)

### 7.1 工具-Agent接口

**工具是确定性系统与非确定性Agent之间的契约。**

与为开发人员设计的传统API不同，工具API必须为推理意图、推断参数值并从自然语言请求生成调用的语言模型而设计。

**工具描述即提示工程**：工具描述被加载到Agent上下文中并共同指导行为。

### 7.2 整合原则

**整合原则**：如果人类工程师不能确定地说在给定情况下应该使用哪个工具，Agent也不能做得更好。

这导致偏好**单个综合工具**而非多个窄工具。

**Vercel d0案例**：
- **之前**：17个专用工具，80%成功率，274秒平均执行
- **之后**：2个工具（bash + SQL），100%成功率，77秒平均执行

**关键洞察**：语义层已经是很好的文档。Claude只需要直接读取文件的权限。

### 7.3 工具描述工程

有效工具描述回答四个问题：

1. **做什么？**：功能的具体描述。避免"有助于"或"可用于"之类的模糊语言。
2. **何时使用？**：具体触发器和上下文。
3. **输入什么？**：带类型、约束和默认值的参数描述。
4. **返回什么？**：输出格式和结构。

**良好设计示例**：

```python
def get_customer(customer_id: str, format: str = "concise"):
    """
    通过ID检索客户信息。

    使用场景：
    - 用户询问特定客户详细信息
    - 需要决策的客户上下文
    - 验证客户身份

    参数：
        customer_id: 格式"CUST-######"（例如"CUST-000001"）
        format: "concise"获取关键字段，"detailed"获取完整记录

    返回：
        包含请求字段的客户对象

    错误：
        NOT_FOUND: 未找到客户ID
        INVALID_FORMAT: ID必须匹配CUST-######模式
    """
```

### 7.4 响应格式优化

实现响应格式选项给Agent控制详细程度的权限：

| 格式 | 用途 |
|-----|------|
| **简洁** | 关键字段仅用于确认或基本信息 |
| **详细** | 决策需要完整上下文时的完整对象 |

---

## 第八部分：文件系统作为上下文层

### 8.1 便签本模式

**问题**：工具调用可返回大量输出。网络搜索可能返回10k token的原始内容。

**解决方案**：将大型工具输出写入文件而非直接返回到上下文。Agent使用目标检索（grep、特定行读取）仅提取相关部分。

**实现示例**：

```python
def handle_tool_output(output: str, threshold: int = 2000) -> str:
    if len(output) < threshold:
        return output

    # 写入便签本
    file_path = f"scratch/{tool_name}_{timestamp}.txt"
    write_file(file_path, output)

    # 返回引用而非内容
    key_summary = extract_summary(output, max_tokens=200)
    return f"[输出已写入{file_path}。摘要:{key_summary}]"
```

### 8.2 计划持久化

**问题**：长期任务需要Agent制定计划并遵循，但对话扩展时计划可能脱离注意力或因摘要而丢失。

**解决方案**：将计划写入文件系统。Agent可以随时重新阅读其计划，提醒自己当前目标和进度。

```yaml
# scratch/current_plan.yaml
objective: "重构认证模块"
status: in_progress
steps:
  - id: 1
    description: "审计当前认证端点"
    status: completed
  - id: 2
    description: "设计新令牌验证流程"
    status: in_progress
  - id: 3
    description: "实现和测试更改"
    status: pending
```

### 8.3 子Agent通信

**问题**：子Agent通常通过消息传递向协调者Agent报告发现，这会在每次跳转时通过摘要造成"传声筒"问题。

**解决方案**：子Agent将其发现直接写入文件系统。协调者直接读取这些文件，绕过中间消息传递。

```
workspace/
  agents/
    research_agent/
      findings.md        # 研究Agent写入
      sources.jsonl      # 源追踪
    code_agent/
      changes.md         # 代码Agent写入
      test_results.txt   # 测试输出
  coordinator/
    synthesis.md         # 协调者读取Agent输出，写入综合
```

### 8.4 动态技能加载

**问题**：Agent可能有许多技能或指令集，但大多数与任何给定任务无关。

**解决方案**：将技能存储为文件。静态上下文中仅包含技能名称和简要描述。

```markdown
可用技能（使用read_file在相关时加载）：
- database-optimization: 查询调优和索引策略
- api-design: REST/GraphQL最佳实践
- testing-strategies: 单元测试、集成测试和端到端测试模式
```

Agent仅在处理数据库任务时加载`skills/database-optimization/SKILL.md`。

---

## 第九部分：评估框架

### 9.1 多维评估量表

Agent质量不是单一维度。有效量表涵盖：

| 维度 | 描述 |
|-----|------|
| **事实准确性** | 声明与基本真相匹配 |
| **完整性** | 输出涵盖请求的方面 |
| **引用准确性** | 引用与声称的来源匹配 |
| **源质量** | 使用适当的主要来源 |
| **工具效率** | 以合理次数使用正确的工具 |

### 9.2 LLM-as-Judge

LLM评估可扩展到大型测试集并提供一致的判断。

**关键**：设计捕获感兴趣维度的有效评估提示。

提供：
1. 清晰的任务描述
2. Agent输出
3. 基本真相（如可用）
4. 带级别描述的评估量表
5. 请求结构化判断

### 9.3 测试集设计

**复杂度分层**：测试集应跨越复杂度级别：

| 级别 | 描述 |
|-----|------|
| **简单** | 单个工具调用 |
| **中等** | 多个工具调用 |
| **复杂** | 许多工具调用、显著模糊 |
| **非常复杂** | 扩展交互、深度推理 |

### 9.4 性能驱动因素发现

BrowseComp评估研究发现：**Token用量解释80%的性能方差**。

**含义**：
- Token预算很重要
- 模型升级胜过token增加
- 多Agent方法得到验证

---

## 第十部分：项目开发方法论

![流水线五阶段](/MyBlog/images/agent-context-engineering/pipeline.png)

### 10.1 任务-模型契合度评估

**LLM适合的任务特征**：

| 特征 | 原因 |
|-----|------|
| 跨源综合 | LLM擅长结合多个输入的信息 |
| 带量化的主观判断 | LLM处理评分、评估和分类 |
| 自然语言输出 | 目标是人类可读文本 |
| 错误容忍 | 单个失败不会破坏整个系统 |
| 批处理 | 项目间无需对话状态 |
| 训练中的领域知识 | 模型已有相关上下文 |

**LLM不适合的任务特征**：

| 特征 | 原因 |
|-----|------|
| 精确计算 | 数学、计数和精确算法不可靠 |
| 实时要求 | LLM延迟对于亚秒响应太高 |
| 完美准确性要求 | 幻觉风险使100%准确不可能 |
| 专有数据依赖 | 模型缺乏必要上下文 |
| 顺序依赖 | 每步严重依赖前一步结果 |
| 确定性输出要求 | 相同输入必须产生相同输出 |

### 10.2 手动原型验证步骤

**在投入自动化之前，通过手动测试验证任务-模型契合度。**

将一个代表性示例复制到模型接口中。评估输出质量。这需要几分钟但可以防止数小时的浪费开发。

**验证回答的关键问题**：
1. 模型是否有此任务所需的知识？
2. 模型能否产生你需要的格式的输出？
3. 规模上应该期望什么质量水平？
4. 有没有明显的失败模式需要解决？

### 10.3 流水线架构

LLM项目受益于分阶段流水线架构，每个阶段都是：
- **离散的**：阶段之间有清晰边界
- **幂等的**：重新运行产生相同结果
- **可缓存的**：中间结果持久化到磁盘
- **独立的**：每个阶段可以单独运行

**规范流水线结构**：

```
acquire → prepare → process → parse → render
```

1. **Acquire（获取）**：从来源获取原始数据（API、文件、数据库）
2. **Prepare（准备）**：将数据转换为提示格式
3. **Process（处理）**：执行LLM调用（昂贵、非确定性的步骤）
4. **Parse（解析）**：从LLM输出提取结构化数据
5. **Render（渲染）**：生成最终输出（报告、文件、可视化）

### 10.4 文件系统状态机

使用文件系统跟踪流水线状态而非数据库或内存结构。

```
data/{id}/
├── raw.json         # acquire阶段完成
├── prompt.md        # prepare阶段完成
├── response.md      # process阶段完成
├── parsed.json      # parse阶段完成
```

**检查项目是否需要处理**：检查输出文件是否存在。
**重新运行阶段**：删除其输出文件和下游文件。
**调试**：直接读取中间文件。

**此模式提供**：
- 自然幂等性（文件存在性门控执行）
- 易于调试（所有状态是人类可读的）
- 简单并行化（每个目录独立）
- 微不足道的缓存（文件在运行间持久化）

### 10.5 结构化输出设计

**有效结构规范包括**：

1. **章节标记**：用于解析的明确页眉或前缀
2. **格式示例**：准确展示输出应该是什么样子
3. **理由披露**："我将编程方式解析此内容"
4. **约束值**：枚举选项、评分范围、格式

**示例提示结构**：

```markdown
分析以下内容并以完全此格式提供响应：

## 摘要
[您的摘要在此]

## 评分
评级：[1-10]

## 详情
- 关键点1
- 关键点2

完全遵循此格式，因为我将编程方式解析它。
```

### 10.6 成本估算

LLM处理具有可预测的成本，应在开始之前估算。

```
总成本 = (项目 × tokens_per_item × price_per_token) + API开销
```

**对于批处理**：
1. 估算每项输入token（提示 + 上下文）
2. 估算每项输出token（典型响应长度）
3. 乘以项目数量
4. 为重试和失败添加20-30%缓冲

**如果成本显著超过估计，重新评估方法**：
- 通过截断减少上下文长度
- 对较简单项目使用较小模型
- 缓存和重用部分结果
- 并行处理以减少挂钟时间（非token成本）

---

## 总结

上下文工程是Agent系统设计的核心方法论。它涵盖从基础理解、退化模式识别，到压缩优化、多Agent架构、记忆系统、工具设计和项目开发的完整体系。

**关键原则回顾**：

1. **上下文质量 > 数量**：信息性原则胜过穷尽性原则
2. **渐进式披露**：仅在需要时加载信息
3. **上下文隔离**：多Agent的主要目的是上下文隔离，而非角色拟人化
4. **简单开始，渐进复杂**：从文件系统记忆开始，仅在检索失败时增加结构
5. **工具整合**：单个综合工具优于多个窄工具
6. **结构强制保留**：专用部分充当检查清单，防止信息漂移
7. **文件系统即状态机**：使用文件系统进行状态跟踪，而非数据库
8. **手动原型验证**：在投入自动化之前验证任务-模型契合度

**设计决策指南**：

| 决策点 | 简单 | → | 复杂 |
|-------|------|---|------|
| 记忆 | 文件系统 | → | 向量存储 | → | 时序知识图谱 |
| Agent架构 | 单Agent | → | 监督者 | → | 对等群体 |
| 工具设计 | 通用原语 | → | 综合工具 | → | 专用工具集 |
| 上下文管理 | 静态 | → | 动态加载 | → | 压缩+分区 |

---

## 参考资料

本文内容基于开源项目 [Agent-Skills-for-Context-Engineering](https://github.com/anthropics/agent-skills) 的源代码分析。

该项目被北京大学通用人工智能国家重点实验室的研究论文引用，作为静态技能架构的基础性工作。

**相关技能模块**：
- context-fundamentals：上下文基础
- context-degradation：退化模式
- context-compression：压缩策略
- context-optimization：优化技术
- multi-agent-patterns：多Agent架构
- memory-systems：记忆系统
- tool-design：工具设计
- filesystem-context：文件系统上下文
- evaluation：评估框架
- project-development：项目开发方法论

---

*本文发表于2026年2月25日，作者基于Agent-Skills-for-Context-Engineering项目的源代码分析撰写。*
