---
title: "ReAct 智能体框架"
date: "2025-11-17"
tags: ["ReAct", "智能体", "大语言模型"]
excerpt: "这是一篇介绍ReAct智能体框架的文章。"
---

# ReAct 智能体框架：从论文到开源实践，以及如何用 Claude Code SDK 入门

过去两年里，**“Agent / 智能体”** 一直是大模型应用里最热的方向之一：会自己思考、会自己调用工具、还能自己反思纠错。大部分“会用工具的 LLM”背后，其实都在不同程度上借鉴了一个核心范式——**ReAct（Reasoning + Acting）**。

这篇文章会系统地讲清楚几件事：

- **ReAct 最初是在什么背景下被提出的？论文到底在解决什么问题？**
- **一个 ReAct 智能体在工程上长什么样：需要哪些模块、怎样组织循环？**
- **目前有哪些代表性的开源 Agent / 框架在用 ReAct 思路？它们的技术细节有什么借鉴意义？**
- **如果你想用 “Claude Code SDK” 搭一个自己的 ReAct 风格智能体，该从哪里下手？**

读完之后，你应该能做到：

1. 看懂别人 Agent 框架里的核心设计；
2. 自己设计出一个简单但完整的 ReAct 智能体循环；
3. 清楚在 Claude Code SDK 这类 SDK 里，怎么把 ReAct 思路落到代码里。

---

## 一、从 ReAct 论文开始：为什么要“推理 + 行动”？

ReAct 这个名字来自一篇非常有代表性的论文：**《ReAct: Synergizing Reasoning and Acting in Language Models》**（Yao 等人）。这篇工作想解决的是一个当时非常现实的问题：

- 纯 **Chain-of-Thought（CoT）推理** 虽然能让 LLM 把思考过程写出来，但模型依然被 **“困在脑子里”**——它看不到环境，也不会操作外部工具；
- 纯 **工具调用 / API 调用**（例如只让模型生成“命令”去执行）又容易变成 **盲目试错**——模型其实不知道自己为什么要这么做，也不会做更深层的计划。

作者提出：与其在“只思考”和“只行动”之间二选一，不如干脆让模型**在一个统一的轨迹（trace）里交替进行**：

```text
Thought 1: 我需要先查一下这个实体的维基百科信息。
Action 1: search[“ReAct: Synergizing Reasoning and Acting in Language Models”]
Observation 1: ……（搜索结果摘要）
Thought 2: 从结果看，这篇论文发表于 2022 年……
Action 2: …
Observation 2: …
…
```

这个轨迹里有三种关键元素：

- **Thought（推理）**：模型以自然语言解释自己“下一步想做什么，以及为什么这么做”；
- **Action（行动）**：模型选择一个工具（search / calculator / API 等）并给出参数；
- **Observation（环境反馈）**：外部世界（搜索引擎、数据库、环境模拟器等）把结果写回给模型。

论文里证明了两件非常重要的事情：

1. **把“思考过程”显式写出来再去调用工具，可以显著提高任务成功率**。模型不再是“黑箱地随机构造 API 请求”，而是有目标、有计划地行动。
2. **统一的自然语言轨迹可以被人类、也可以被另一个模型检查和反思**。这为后续的“反思型 Agent”（Self-Refine、Reflexion 等）提供了基础。

换句话说，ReAct 给我们提供了一种 **“让语言模型像人类一样边想边做”** 的工程模板。

---

## 二、抽象一个通用的 ReAct 智能体循环

如果把论文思想翻译成工程代码，一个典型的 ReAct 智能体大致长这样：

1. **初始化上下文**
   - 任务描述（用户指令）
   - 当前环境状态（可选）
   - 可用工具列表（name + 描述 + 参数格式）

2. **主循环（Reasoning–Acting–Observing Loop）**
   1. 把历史轨迹（Thought/Action/Observation 序列） + 工具说明 + 任务目标，拼成一个 prompt 发给 LLM；
   2. 让 LLM 生成下一步的 **Thought** 和 **Action**；
   3. 解析 Action，调用对应工具，得到 **Observation**；
   4. 把 Observation 追加到轨迹中，如果达到终止条件（DONE / 达成目标 / 步数上限），停止循环。

3. **输出结果**
   - 把最后的 Thought 或特定格式的 Answer 提取出来，返回给用户或下游系统。

如果用伪代码表示：

```text
state = {goal, tools, history=[]}
for step in range(max_steps):
  prompt = build_prompt(state)
  llm_output = call_llm(prompt)
  thought, action = parse(llm_output)

  if action.type == "finish":
    return action.output

  observation = run_tool(action)
  state.history.append({thought, action, observation})
```

**几个工程上必须考虑的问题：**

- **Action 的结构化表示**  
  - 早期做法：完全靠正则从 LLM 文本里抽取 `Action: search[xxx]`；
  - 后来逐渐演化为：**函数调用 / 工具调用协议**，例如 OpenAI function calling、Anthropic 工具调用、MCP 等，让模型直接输出结构化 JSON。

- **错误与异常处理**  
  - 工具失败（网络错误 / API 限流）怎么办？
  - 模型输出不合法参数怎么办？
  - 常见做法：在 Observation 中显式反馈错误信息，让模型自己修正参数，配合重试上限。

- **记忆（Memory）与长期状态**  
  - 单轮 ReAct 循环只维护“本次任务的轨迹”，但实际应用常常需要跨会话、跨任务的记忆；
  - 常见做法是：把 ReAct 循环看作 “短期工作记忆（Working Memory）”，长期记忆由向量库 / 数据库存储，再作为一种“工具”提供给 Agent。

只要你掌握了这套循环模板，理解任何一个 Agent 框架的核心实现就会轻松很多——大家本质上都是在这个范式上做工程优化。

---

## 三、开源世界里的 ReAct 与 Agent：几个有代表性的案例

下面选几个比较有代表性的开源 / 公开项目，从 **“ReAct 思路是怎么在代码里落地的”** 这个角度拆解一下。

> 说明：很多项目名字不一定直接叫 “ReAct”，但只要它在“自然语言推理 + 工具调用 + 环境反馈 + 再推理”这个闭环上做文章，基本都属于 ReAct 范式家族。

### 3.1 LangChain Agents（ReAct 的最流行落地之一）

虽然这里不展开具体代码，但 LangChain 的 Agent 体系是业界比较早系统实现 ReAct 思路的框架之一，核心设计非常有代表性：

- **工具（Tool）是第一等公民**：每个 Tool 有 `name / description / args`，并且会自动在 prompt 里展示给 LLM。
- **Agent 决策逻辑是“prompt + 解析器”**：
  - prompt 模板里显式告诉 LLM：你有这些工具，可以按特定格式写 `Thought` 和 `Action`；
  - 解析器负责从模型输出中抽取结构化的 Action，调用工具，再把结果以 `Observation` 形式回写。
- **支持多种 Agent 模式**：
  - “ReAct 风格”只是其中一个，另外还有规划式、聊天式等，但本质上都是对“推理 + 行动”循环的不同包装。

从 ReAct 学到的一点是：**不要把工具调用写死在业务逻辑里，而是把“该不该调用工具、调用哪个工具”交给模型自己决定**。这也是大部分 Agent 框架现在的基本共识。

### 3.2 AgentScope：工程化很强的 ReAct 智能体框架

AgentScope 是一个国产团队开源的智能体框架，官方文档里明确强调了 ReAct 风格的任务代理（task agent）。从工程角度看，有几个特别值得学习的点：

- **模块化任务 Agent**：  
  把“任务理解、计划、执行、反思”等职责拆成多个可插拔的 Agent，对复杂业务场景更友好。

- **并行工具调用与流式反馈**：  
  - 对于 I/O 密集型工具（搜索、联网 API），AgentScope 支持并行调用；
  - 结果可以渐进式地流回给用户，提升交互体验。

- **工具与环境的抽象层**：  
  - 把“真实世界 API / 内部服务 / 数据库”等统一封装成 Tool；
  - 对上层的 ReAct Agent 来说，只是调用不同的 Action，不必关心具体协议。

换句话说，AgentScope 做的是：**在保持 ReAct 思路（推理 + 行动循环）不变的前提下，把“工程这一侧”做到工业级可用**。

### 3.3 基于 ReAct 思路的代码生成 Agent（以 RA-Gen 系一类工作为例）

在代码生成场景里，很多工作会采用多 Agent + ReAct 的组合，例如像 RA-Gen 这样把任务拆成几个协作的角色：

- **Planner（规划者）**：  
  - 根据需求把任务拆成若干子任务；
  - 决定大致解决路径（比如先分析接口、再设计数据结构、再写业务逻辑）。

- **Searcher（信息搜索 / 检索 Agent）**：  
  - 采用 ReAct 循环：Thought → Action(search / read_file / grep) → Observation；
  - 不断查找相关代码、文档、API 定义。

- **Coder（代码生成 Agent）**：  
  - 综合 Planner 的计划和 Searcher 找到的信息，生成代码；
  - 同样可以用 ReAct 思路调用编译器 / 测试框架等工具。

- **Reviewer / Refiner（审查 / 反思 Agent）**：  
  - 检查代码质量、运行结果；
  - 给出修改意见，再交回 Coder 迭代。

这里几个经验非常值得参考：

1. **复杂问题尽量拆成多 Agent 协作，每个 Agent 内部再用 ReAct 循环。**  
   ReAct 更适合做“在某个明确子任务范围里的推理 + 行动闭环”；
2. **工具不仅是 HTTP API，IDE 内的操作、测试命令、代码重排等都可以是工具。**  
   这样 Agent 真正具备“操作代码环境”的能力。

---

## 四、从“ReAct 思路”到“Claude Code SDK”：怎么把它变成可运行的 Agent？

上面讲的更多是概念和框架，这一节我们回到本文最实用的部分：**如果你想用 Claude Code SDK 这类 SDK 做一个 ReAct 风格的智能体，应该关注哪些点？**

> 下面不会写死具体的类名 / API，而是给出一个足够通用、又贴近实际实现的思路，让你在看官方文档或示例时有“带着问题去看”的框架。

### 4.1 把 LLM + 工具抽象成一个“可对话的环境”

在 Claude Code SDK 这类 SDK 里，一般会提供：

- **一个统一的“对话 / 请求”入口**：  
  - 你传入：系统提示词、用户消息、历史对话；
  - SDK 帮你调用 Claude 模型，并返回模型回复；
  - 如果启用了工具 / MCP，模型还可以在回复中触发工具调用。

- **工具 / MCP 适配层**：  
  - 你注册若干个“工具实现”（例如本地文件读写、调用某个 HTTP 服务、访问数据库）；
  - SDK 把它们描述成一种通用的工具协议，暴露给模型；
  - 当模型在输出里声明要调用某个工具时，SDK 会回调你提供的实现。

从 ReAct 的视角看，这其实已经给我们提供了一个**天然的“Action → Observation 执行层”**：

- 模型输出里出现“我要调用工具 X，参数是 Y”；
- SDK 帮你执行工具 X(Y)，拿到结果；
- 再把结果作为 Observation 追加进后续的模型上下文。

也就是说，**你不需要自己从头实现“解析 Action、调起工具、写回 Observation 的协议”，SDK 已经帮你做了 80% 的工作**，你要做的是：

- 设计好高层的 ReAct Prompt；
- 设计好工具集合（有哪些工具、权限边界如何）；
- 在需要的时候控制循环（什么时候继续、什么时候终止）。

### 4.2 设计一个 ReAct 风格的系统 Prompt

无论你用的是哪家 SDK，要想让模型遵守 ReAct 轨迹，第一件事都是**写好系统提示词**。一个最小可用的 ReAct Prompt 一般包含：

1. **角色设定**：你是一个会分步思考并使用工具的智能体；
2. **工具使用规则**：什么时候应该调用工具、应该如何组合工具；
3. **输出格式约定**：必须按 `Thought: ...` / `Action: ...` / `Observation: ...` 的结构输出；
4. **终止条件**：当你认为任务完成时，用 `Action: finish[最终答案]` 结束。

在支持结构化工具调用的 SDK 里，你可以简化为：

- Thought 用自然语言；
- Action 则通过“工具调用 JSON”自动触发，无需你再用正则提取。

这一步很重要：**Prompt 是整个 ReAct Agent 行为的“操作手册”**，直接决定：

- 模型会不会乱调用工具；
- 会不会浪费很多步做无用思考；
- 会不会在该用工具的时候不去查证，导致幻觉。

### 4.3 在代码里实现 ReAct 控制循环

即使 SDK 已经帮你处理工具调用，你依然需要一个显式的“任务循环控制器”（Controller），大致职责是：

- 执行若干轮“与模型对话”（每轮都可能触发 0~多次工具调用）；
- 解析模型是否已经“完成任务”；
- 根据任务类型决定是否继续追问 / 细化。

一个简单的控制逻辑可以是：

1. 初始化一个会话（可以带上长上下文、项目代码、配置等）；
2. 循环：
   - 把用户任务 / 当前子任务丢给模型；
   - 等待模型回复（期间 SDK 可能多次调用工具）；
   - 检查回复内容：是“最终答案”还是“中间步骤说明”；
   - 如果是中间步骤，记录下来，必要时根据你的业务逻辑拆成新的子任务；
3. 返回最后的答案或某种结构化结果。

在 Claude Code SDK 所在的 IDE / 本地环境中，你还可以进一步：

- 把“运行测试、查看错误堆栈、打开文件、修改代码”等都包装成工具；
- 允许模型在一次任务里多次执行“修改代码 → 运行测试 → 阅读报错 → 再修改”的 ReAct 闭环。

这实际上就是你现在在 IDE 里体验到的“智能写代码”的典型工作方式。

### 4.4 安全与约束：给 ReAct Agent 画边界

ReAct 的威力很大，但同样也需要 **边界与约束**，尤其是当 Agent 拥有“写文件、发网络请求、操作生产服务”等能力时。

常见的做法包括：

- **最小工具集原则**：  
  - 只给当前任务必要的工具；
  - 避免把“毁灭世界的按钮”放到默认工具列表里。

- **只读 / 只写分离**：  
  - 把工具区分为“只读（inspect / search）”和“有副作用（write / delete / deploy）”；
  - 对有副作用的操作增加额外确认，甚至需要人工 review。

- **结果审计与日志记录**：  
  - 对每次 Thought / Action / Observation 轨迹做持久化；
  - 方便事后追踪问题，也方便模型自身做反思或微调数据构建。

这些原则，对用 Claude Code SDK 构建 Agent 同样适用：**越强大的 Agent，越需要被小心、细致地约束在合理的权限边界内。**

---

## 五、一个“从 0 到 1” 的入门路径建议

如果你已经看完这里，想真正 **“动手做一个小 Agent 玩玩”**，这里给出一条比较现实、也比较符合学习曲线的路线——你可以直接对照执行。

### 步骤 1：用纯对话实现一个“纸面 ReAct Agent”

不写任何代码，只用 Chat 界面或命令行：

1. 自己写一个简单的 ReAct Prompt；
2. 手工扮演“工具”和“环境”：
   - 模型说 `Action: search[xxx]`，你自己去搜，然后把结果贴回去当 `Observation`；
3. 看看模型是否能在 3～5 步内解决一个小任务（比如查资料、三步推理题）。

这个练习会让你非常直观地感受到：**ReAct 的本质其实就是“对话版的程序化推理”**。

### 步骤 2：用 Claude Code SDK + 少量工具，包一层最小 ReAct 循环

选择你最熟悉的语言（通常是 TypeScript / JavaScript），参考 SDK 文档：

1. 注册几个简单工具：
   - 例如：本地文件读取 / 写入、执行测试命令、HTTP GET 请求等；
2. 实现一个最小的控制循环：
   - 把用户任务、工具说明、历史轨迹拼成 prompt；
   - 发送给模型，监听 SDK 发来的工具调用回调；
   - 执行工具，回写结果，再继续下一轮。

先把目标定得非常小：**让 Agent 能帮你完成一个具体但可控的小任务**，比如：

- “阅读项目里的 `README.md` 和某个配置文件，总结出服务在多少端口启动”；
- “在现有测试里加一个断言，并确保测试通过”；
- “根据某个接口文档生成一份 TypeScript 类型定义”。

### 步骤 3：逐步引入“多 Agent + 反思 / 计划”等高级能力

当你对最小 ReAct Agent 比较熟悉后，就可以考虑加一点“论文里的高级玩法”：

- **引入 Planner / Reviewer 等角色**：  
  - Planner 只负责拆解任务；  
  - Worker 负责具体 ReAct 执行；  
  - Reviewer 对结果做审查和反馈。

- **用 ReAct 轨迹做“自我反思”**：  
  - 把历史的 Thought / Action / Observation 丢给另一个模型（或者同一个模型），让它总结“哪里做错了、下次可以怎么改”；
  - 把这些反思结果当作新的系统提示词的一部分，改善后续表现。

- **把 ReAct 轨迹落盘做训练 / 对齐数据**：  
  - 如果你后面要做更深入的二次训练 / RLAIF / Preference，ReAct 轨迹是非常好的监督数据来源。

这一步开始，你构建的就不再是“玩具 Agent”，而是可以逐渐演化为一个**真正能帮团队提升效率的工程智能体**。

---

## 六、总结与延伸阅读

我们可以把这篇文章压缩成几句核心结论：

- **ReAct 是近几年 Agent 浪潮里最基础、也最实用的范式之一**：  
  它很简单——“推理 + 行动 + 观察 + 再推理”——但足以支撑从搜索问答到代码生成、从 Web 自动化到多 Agent 协作的大部分场景。

- **从工程角度看，一个 ReAct 智能体至少需要：**  
  - 清晰的工具抽象；  
  - 稳定的 LLM 调用（最好有结构化工具调用能力）；  
  - 一个控制循环（限制步数、控制终止、记录轨迹）；  
  - 基本的错误处理和安全边界。

- **Claude Code SDK 等 SDK 帮你做的是“打通 LLM + 工具 + 环境”这层 plumbing**：  
  在这个基础上，你只需要专注于设计好的 Prompt、好的工具集合，以及合理的任务拆分和循环控制，就能搭出自己风格的 ReAct Agent。

如果你想继续深入，建议的阅读 / 实践顺序可以是：

1. 通读 ReAct 原始论文（重点看实验设置与 Prompt 设计）；
2. 选一个开源 Agent 框架（比如 AgentScope / LangChain Agents），跟着官方教程跑一两个例子；
3. 结合 Claude Code SDK 的示例，亲手实现一个“会自己读代码、改代码、跑测试”的小型 ReAct 智能体；
4. 把你自己项目的真实需求一点点搬上去，让 Agent 逐步从“玩具”变成团队日常工作流的一部分。

当你能独立完成上面这些步骤时，你就不仅是“会用大模型的人”，而是真正掌握了 **“如何让大模型变成一个可控、可解释、可扩展的智能体”** 的工程能力了。


