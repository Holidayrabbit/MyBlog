---
title: "LLMDroid：用大语言模型高效增强移动应用GUI测试覆盖率"
excerpt: "深度解析LLMDroid框架如何通过自主探索与LLM引导的双阶段策略，在降低成本的同时显著提升Android应用测试覆盖率"
date: "2026-02-21"
tags: ["paper", "Software", "LLM"]
---

## 论文概览

**论文标题**: LLMDroid: Enhancing Automated Mobile App GUI Testing Coverage with Large Language Model Guidance

**发表会议**: Proceedings of the ACM on Software Engineering (FSE 2025)

**作者**: Chenxu Wang (华中科技大学), Tianming Liu (莫纳什大学), Yanjie Zhao (华中科技大学), Minghui Yang (OPPO), Haoyu Wang (华中科技大学)

**核心贡献**: 提出了一个创新的测试框架LLMDroid，通过高效利用大语言模型来增强现有的移动应用GUI自动化测试工具，在显著提升代码覆盖率的同时大幅降低了LLM交互成本。

## 研究背景与动机

### 现有问题

当前基于LLM的移动应用测试方法（如GPTDroid和DroidAgent）面临两个核心挑战：

1. **时间效率低下**: 采用逐步LLM引导模式，每个测试动作都需要查询LLM，导致响应时间长、端到端延迟高
2. **成本高昂**: 持续的LLM查询在长时间测试中产生巨大的经济成本，阻碍了这些方法的广泛应用

传统的自动化测试工具（基于模型、深度学习或强化学习）虽然执行速度快，但常常陷入循环或过度关注有限的应用页面子集，测试覆盖率提升空间大。

### 核心洞察

LLMDroid的关键创新在于：**不是让LLM参与每一步测试决策，而是让传统工具自主探索，仅在覆盖率增长停滞时才请求LLM指导**。这种设计在保持LLM语义理解优势的同时，最大化了传统工具的执行效率。

## 方法设计

LLMDroid的工作流程分为两个主要阶段，交替执行直到测试时间耗尽：

### 阶段一：自主探索 (Autonomous Exploration)

在此阶段，LLMDroid利用现有测试工具自主探索应用，同时包含两个关键模块：

#### 1. GUI摘要模块

**UI页面聚类**:
- 使用Dice系数计算页面相似度：`2|A∩B| / (|A|+|B|)`
- 相似页面合并为PageCluster，每个cluster只有一个根页面
- 仅对根页面进行LLM摘要，大幅减少LLM交互次数

**功能导向的重要性感知提示设计**:
- 将UI页面转换为HTML格式描述（更符合LLM训练数据分布）
- 要求LLM生成页面概述（30字以内）
- 分析并列出页面功能，按重要性排序：
  - 导航相关功能（可能触发新页面）
  - 应用核心功能
- 评估页面在整个应用中的重要性，维护Top P₁重要页面列表

**提示时机优化**:
- 新PageCluster建立时立即查询LLM（高优先级）
- LLM空闲时补充分析非根页面的独特控件（低优先级）
- 在测试初期频繁发现新页面时多查询，后期覆盖率瓶颈时减少查询

#### 2. 覆盖率监控模块

**动态阈值机制**:
- 计算相邻覆盖率数据点的增长率：`gᵢ = (cᵢ - cᵢ₋₁) / cᵢ₋₁`
- 维护动态基线增长率：`G = (g₁ + g₂ + ... + gₙ₋₁) / (n-1)`
- 使用指数函数动态调整阈值：`Tₙ = Tₙ₋₁ · e^(Δg)`，其中`Δg = gₙ - G`
- 设置窗口大小W=80，当窗口内所有增长率都低于动态阈值时触发LLM引导

**设计理念**:
- 初始阈值T₀=0.05，最小阈值0.01
- 当增长率高于平均时提高阈值，低于平均时降低阈值
- 适应测试进程中覆盖率增长自然放缓的趋势

### 阶段二：LLM引导 (LLM Guidance)

当检测到覆盖率增长停滞时，进入此阶段突破瓶颈：

#### 1. 目标选择模块

- 向LLM提供Top P₂（=10）重要页面及其Top Q₂（=5）未测试功能
- 指示LLM优先选择导航相关功能或可能触发新页面的功能
- LLM返回目标页面和目标功能

#### 2. 离线页面导航模块

**关键设计决策**: 不依赖LLM进行导航，而是利用自主探索阶段的历史轨迹本地完成

**导航策略**:
- 重启应用从初始页面开始
- 使用Dijkstra算法在UI页面转换图上计算最短路径
- 实现三种优化策略：
  - **模糊匹配**: 使用页面相似度计算处理动态页面变化
  - **步骤跳过**: 当前页面不匹配时检查是否匹配后续页面
  - **失败处理**: 尝试最近建立的路径，每次失败降低相似度阈值0.05

**重试机制**: 最多尝试3次导航，失败后让LLM重新选择目标（最多3次），全部失败则返回自主探索

#### 3. 引导功能执行模块

- 到达目标页面后，与LLM进行逐步对话执行目标功能
- 每步提供当前页面HTML描述和已执行动作
- 询问LLM功能是否完成，若未完成则获取下一步动作
- 限制最多5步（考虑到逐步引导的时间成本）

执行完成后返回自主探索阶段，从当前页面继续快速探索。

## 实验设计

### 实现与工具选择

**应用对象**: 将LLMDroid应用于三个流行的开源Android测试工具：
- **Droidbot**: 基于模型的方法
- **Humanoid**: 基于深度学习（基于Droidbot）
- **Fastbot**: 基于强化学习（字节跳动开发）

这三个工具代表了自动化测试的三大主流技术路线。

**覆盖率监控**:
- 使用AndroLog进行黑盒代码覆盖率分析（基于Soot的静态APK插桩）
- 选择方法级粒度平衡精度和开销
- 同时提供基于JaCoCo的白盒版本

### 实验数据集

**创新之处**: 不同于以往研究使用开源应用，本研究主要从Google Play热门榜单选择闭源商业应用

**数据集构成**: 14个应用，涵盖多个流行类别：
- 购物（Wish: 5亿+下载）
- 娱乐（Twitch: 1亿+下载）
- 教育（Wikipedia, Quora: 5000万+下载）
- 工具（Fing, Time Planner）
- 健康（Lefun Health, Renpho Health）
- 新闻、体育、图书等

**选择理由**: 商业应用更能代表真实世界测试场景的规模和复杂度

### 实验配置

- **设备**: Google Pixel 4, Android 11
- **测试时长**: 每个应用60分钟（业界标准）
- **动作间隔**: 3秒
- **重复次数**: 每个工具在每个应用上运行3次，取最高覆盖率
- **页面相似度阈值**: Tₛ = 0.6（通过实验确定）
- **主要LLM**: GPT-4o（同时评估GPT-3.5-turbo和GPT-4o-mini）

## 实验结果

### RQ1: LLMDroid的增强效果

**整体改进**:
- 平均代码覆盖率提升：**26.16%**
- 平均Activity覆盖率提升：**29.31%**
- 最显著改进：代码覆盖率提升30.30%（Fastbot），Activity覆盖率提升41.29%（Droidbot）

**各工具表现**:
| 工具 | 原始代码覆盖率 | LLMDroid增强后 | 提升率 |
|------|---------------|---------------|--------|
| Droidbot | 9.21% | 11.69% | 26.90% |
| Humanoid | 11.05% | 13.40% | 21.29% |
| Fastbot | 11.36% | 14.80% | **30.30%** |

**改进分布**: 在42个数据点中：
- 仅16.67%的改进率低于10%
- 近半数（47.62%）超过20%
- 显示出跨应用和工具的稳定性能

**LLM引导有效性分析**:
- 平均每小时触发LLM引导：Fastbot 9.17次，Droidbot 6.42次，Humanoid 6.17次
- 整体有效率：**47.84%**
- 各工具有效率：Humanoid 55.00% > Droidbot 48.24% > Fastbot 42.48%

**失败原因分析**:
- 离线导航失败：12.11%
- 引导至新页面但无效：18.14%
  - A1: 新页面探索不充分
  - A2: 新页面本身潜力有限
- 未能引导至新页面：69.75%
  - B1: LLM误解UI控件功能
  - B2: 导航至已探索页面
  - B3: 选择未探索功能但未触发新页面
  - B4: 选择其他页面已探索的功能

### RQ2: 不同LLM下的性能与成本

**代码覆盖率对比**（LLMDroid-Fastbot vs 最佳基线工具）:
| LLM模型 | 代码覆盖率 | 相比基线提升 | 相比原始Fastbot提升 |
|---------|-----------|-------------|-------------------|
| GPT-4o | 14.33% | 31.59% | 26.14% |
| GPT-4o-mini | 13.47% | 23.69% | 18.57% |
| GPT-3.5-turbo | 13.01% | 19.47% | 14.52% |

**成本效率对比**（每小时成本）:
| 方法 | LLM | 代码覆盖率 | 成本 | 交互次数 | 阻塞时间 |
|------|-----|-----------|------|---------|---------|
| DroidAgent | GPT-3.5 | 10.77% | $1.721 | 1761 | 69.7% |
| DroidAgent | GPT-4o-mini | 10.89% | $1.086 | 1692 | 76.7% |
| GPTDroid | GPT-3.5 | 7.43% | $0.207 | 724 | 59.2% |
| **LLMDroid** | **GPT-4o** | **14.33%** | **$0.49** | **102** | **3.0%** |
| **LLMDroid** | **GPT-4o-mini** | **13.47%** | **$0.03** | **101** | **3.4%** |
| **LLMDroid** | GPT-3.5 | 13.01% | $0.09 | 95 | 2.7% |

**关键发现**:
1. **成本效率惊人**: 使用GPT-4o-mini时，LLMDroid以仅$0.03/小时的成本达到GPT-4o性能的94%（GPT-4o成本的6.7%）
2. **交互频率大幅降低**: LLMDroid每小时约100次交互，而逐步引导方法需要700-1700次
3. **阻塞时间最小化**: LLMDroid的测试阻塞时间仅约3%，而逐步方法达60-70%
4. **性能优势明显**: 即使使用最便宜的GPT-4o-mini，LLMDroid的代码覆盖率仍比DroidAgent（使用GPT-4o-mini）高23.69%，成本仅为其3%

### RQ3: UI页面相似度阈值优化

通过在5个应用上测试不同阈值（0.5, 0.6, 0.7, 0.8），发现：
- **最优阈值**: Tₛ = 0.6
- 更高阈值导致LLM交互过于频繁，成本高且性能下降
- 更低阈值导致页面区分不足，影响摘要质量

## 技术亮点

### 1. 混合策略设计

LLMDroid巧妙平衡了传统工具的执行效率和LLM的语义理解能力：
- 自主探索阶段充分利用传统工具的快速执行
- LLM引导阶段利用语义理解突破瓶颈
- 离线导航避免了多步导航中的LLM开销

### 2. 并发执行优化

GUI摘要在自主探索期间并发执行，不阻塞测试进程：
- 高优先级队列：新PageCluster的摘要
- 低优先级队列：补充分析、重新分析
- 测试阻塞时间仅占总时间的3%左右

### 3. 动态自适应机制

- 覆盖率增长阈值根据历史数据动态调整
- 页面重要性排名持续更新
- 导航失败时自动降低相似度阈值重试

### 4. 提示工程

精心设计的提示策略：
- 功能导向：关注可触发新页面的功能
- 重要性感知：维护重要页面和功能列表
- 信息压缩：仅提供Top P页面和Top Q功能，避免信息过载

## 局限性与未来工作

### 1. 代码覆盖率监控问题

- AndroLog虽是最先进的黑盒工具，但部分应用插桩后出现功能异常
- 需要更好的黑盒覆盖率分析方法
- 对于开发者测试自己的应用，可使用JaCoCo等白盒工具

### 2. LLM页面理解能力有限

- 某些控件缺乏语义信息（无文本或难以理解的resource-ID）
- 潜在解决方案：
  - 图像描述模型（如pix2struct）
  - 多模态大模型（如AppAgent, MM-Navigator）
- 当前未采用是因为成本高，与LLMDroid的高效目标相悖

### 3. 参数优化空间

- 多个参数（T₀, P, Q等）基于经验设置
- 参数间可能存在相互依赖关系
- 需要更全面的参数优化实验

### 4. 潜在改进方向

基于失败案例分析的改进建议：
- 更精确定义导航相关功能，结合思维链推理
- 开发关联机制识别不同路径可达的相同页面
- 识别跨页面的相同功能，避免重复推荐

## 研究意义

### 学术价值

1. **新范式**: 提出了一种新的LLM集成范式，不同于现有的逐步引导方法
2. **可复现性**: 开源了三个工具的实现代码、数据集和集成指南
3. **实证研究**: 在真实商业应用上的大规模评估，而非仅在开源应用上测试

### 实用价值

1. **成本效益**: 使用GPT-4o-mini时仅$0.03/小时，使大规模应用成为可能
2. **即插即用**: 可增强现有测试工具，无需从头开发
3. **工业适用**: 在商业应用上验证，更贴近实际测试场景

### 启发意义

LLMDroid的设计理念对其他领域的LLM应用具有借鉴意义：
- **选择性使用LLM**: 不是所有任务都需要LLM参与
- **并发执行**: 将LLM交互与主任务并行，减少阻塞
- **混合策略**: 结合传统方法的效率和LLM的智能
- **成本意识**: 在性能和成本间寻找最佳平衡点

## 个人思考

### 优势

1. **问题定位准确**: 精准识别了现有LLM测试方法的核心痛点（时间和成本）
2. **设计巧妙**: 双阶段交替策略既保留了LLM优势又避免了其劣势
3. **工程完善**: 从页面聚类、动态阈值到离线导航，每个模块都有深思熟虑的设计
4. **评估全面**: 不仅评估性能，还详细分析成本、失败原因和参数影响

### 可能的改进方向

1. **自适应窗口大小**: 当前W=80是固定值，可否根据应用特性动态调整？
2. **学习型导航**: 离线导航失败时，能否让LLM学习失败模式并调整策略？
3. **增量摘要**: 当PageCluster新增页面时，能否增量更新摘要而非重新分析？
4. **多模态集成**: 随着多模态模型成本降低，未来版本可考虑集成视觉理解

### 对测试领域的启示

LLMDroid展示了一个重要趋势：**LLM不应该替代传统方法，而应该增强它们**。这种"AI增强"而非"AI替代"的思路，可能是未来软件工程工具发展的主流方向。

## 结论

LLMDroid是一个设计精巧、实用性强的测试框架，成功解决了LLM集成到移动应用测试中的关键挑战。通过自主探索与LLM引导的双阶段策略，它在显著提升测试覆盖率（平均26.16%）的同时，将成本降低到了可接受的水平（$0.03-0.49/小时）。

这项工作不仅为移动应用测试提供了实用工具，更为如何高效利用LLM增强传统软件工程工具提供了宝贵的设计范式和实践经验。随着LLM技术的持续发展和成本的进一步降低，LLMDroid所代表的混合智能方法有望在更广泛的软件工程领域得到应用。

---

**论文链接**: https://doi.org/10.1145/3715763
**代码仓库**: https://github.com/security-pride/LLMDroid
